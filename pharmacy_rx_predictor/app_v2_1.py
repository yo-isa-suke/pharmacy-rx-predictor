"""
è–¬å±€ å¹´é–“å‡¦æ–¹ç®‹æšæ•° å¤šé¢çš„äºˆæ¸¬ãƒ„ãƒ¼ãƒ« v2.1
==========================================
v2.0ã‹ã‚‰ã®æ”¹å–„ç‚¹:
  1. ã‚¸ã‚ªã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ä¿®æ­£
     - User-Agent ã‚’æ‹¬å¼§ãªã—ã«å¤‰æ›´ï¼ˆNominatim 403ã‚¨ãƒ©ãƒ¼å¯¾ç­–ï¼‰
     - å…¨è§’æ–‡å­—å¤‰æ›ãƒã‚°ä¿®æ­£
     - ãƒ—ãƒ­ã‚°ãƒ¬ãƒƒã‚·ãƒ–ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆãƒ•ãƒ«ä½æ‰€â†’çŸ­ç¸®â†’åŒºå¸‚ã®ã¿ï¼‰
     - åº§æ¨™ã‚µãƒ‹ãƒ†ã‚£ãƒã‚§ãƒƒã‚¯ï¼ˆæ—¥æœ¬å›½å†…130â‰¤lonâ‰¤154, 24â‰¤latâ‰¤46ï¼‰
     - å–å¾—åº§æ¨™ã‚’UIã«è¡¨ç¤º
  2. å•†åœäººå£å¯†åº¦ã‚’ä½æ‰€ã‹ã‚‰è‡ªå‹•è¨ˆç®—
     - æ±äº¬23åŒºãƒ»å¤§é˜ª24åŒºã®åŒºåˆ¥ãƒ‡ãƒ¼ã‚¿ï¼ˆ2020å¹´å›½å‹¢èª¿æŸ»ï¼‰
     - æ”¿ä»¤æŒ‡å®šéƒ½å¸‚ãƒ»ä¸»è¦å¸‚ãƒ¬ãƒ™ãƒ«
     - éƒ½é“åºœçœŒãƒ¬ãƒ™ãƒ«ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
  3. å•†åœåŠå¾„ã‚’é©åˆ‡ãªãƒ­ã‚¸ãƒƒã‚¯ã§è‡ªå‹•è¨ˆç®—
     - é–€å‰è–¬å±€åˆ¤å®šï¼ˆ80mä»¥å†…ã«åŒ»ç™‚æ©Ÿé–¢ or è–¬å±€åã«ã€Œé–€å‰ã€ç­‰ï¼‰â†’ 300må›ºå®š
     - äººå£å¯†åº¦ã«åŸºã¥ãæ®µéšçš„è¨­å®šï¼ˆ12k+â†’300m ... <500â†’2000mï¼‰
     - ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼å»ƒæ­¢ãƒ»è‡ªå‹•è¨ˆç®—ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’UIã«è¡¨ç¤º

ã€æ–¹æ³•â‘ ã€‘è¿‘éš£åŒ»ç™‚æ©Ÿé–¢ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ
  - OpenStreetMap (Overpass API) ã§è¿‘éš£ã‚¯ãƒªãƒ‹ãƒƒã‚¯ãƒ»ç—…é™¢ã‚’æ¤œç´¢
  - åšç”ŸåŠ´åƒçœãƒãƒ¼ã‚¿ãƒ«ã§å„æ–½è¨­ã®å¤–æ¥æ‚£è€…æ•°ã‚’ç…§ä¼š
  - è¨ºç™‚ç§‘åˆ¥å‡¦æ–¹ç®‹ç™ºè¡Œç‡ Ã— é™¢å¤–å‡¦æ–¹ç‡ Ã— ç«¶åˆè–¬å±€ã‚·ã‚§ã‚¢ã‹ã‚‰äºˆæ¸¬

ã€æ–¹æ³•â‘¡ã€‘å•†åœäººå£å‹•æ…‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ
  - å•†åœå†…äººå£æ¨è¨ˆï¼ˆä½æ‰€ã‹ã‚‰è‡ªå‹•è¨ˆç®—ã—ãŸå¯†åº¦ãƒ»åŠå¾„ã‚’ä½¿ç”¨ï¼‰
  - æ€§å¹´é½¢åˆ¥æœ‰ç—…ç‡ãƒ»å—è¨ºç‡ Ã— å‡¦æ–¹ç®‹ç™ºè¡Œç‡ Ã— è–¬å±€ã‚·ã‚§ã‚¢ã‹ã‚‰äºˆæ¸¬

ã€ç«¶åˆãƒãƒƒãƒ—ã€‘Folium (OpenStreetMap) ã§è¿‘éš£åŒ»ç™‚æ–½è¨­ãƒ»è–¬å±€ã‚’å¯è¦–åŒ–
"""

import math
import re
import time
import urllib.parse
from dataclasses import dataclass, field
from typing import Dict, List, Optional, Tuple

import folium
import requests
import streamlit as st
from bs4 import BeautifulSoup
from streamlit_folium import st_folium

# ---------------------------------------------------------------------------
# å®šæ•°ãƒ»çµ±è¨ˆãƒ‡ãƒ¼ã‚¿
# ---------------------------------------------------------------------------

PREFECTURES = [
    "åŒ—æµ·é“", "é’æ£®çœŒ", "å²©æ‰‹çœŒ", "å®®åŸçœŒ", "ç§‹ç”°çœŒ", "å±±å½¢çœŒ", "ç¦å³¶çœŒ",
    "èŒ¨åŸçœŒ", "æ ƒæœ¨çœŒ", "ç¾¤é¦¬çœŒ", "åŸ¼ç‰çœŒ", "åƒè‘‰çœŒ", "æ±äº¬éƒ½", "ç¥å¥ˆå·çœŒ",
    "æ–°æ½ŸçœŒ", "å¯Œå±±çœŒ", "çŸ³å·çœŒ", "ç¦äº•çœŒ", "å±±æ¢¨çœŒ", "é•·é‡çœŒ",
    "å²é˜œçœŒ", "é™å²¡çœŒ", "æ„›çŸ¥çœŒ", "ä¸‰é‡çœŒ",
    "æ»‹è³€çœŒ", "äº¬éƒ½åºœ", "å¤§é˜ªåºœ", "å…µåº«çœŒ", "å¥ˆè‰¯çœŒ", "å’Œæ­Œå±±çœŒ",
    "é³¥å–çœŒ", "å³¶æ ¹çœŒ", "å²¡å±±çœŒ", "åºƒå³¶çœŒ", "å±±å£çœŒ",
    "å¾³å³¶çœŒ", "é¦™å·çœŒ", "æ„›åª›çœŒ", "é«˜çŸ¥çœŒ",
    "ç¦å²¡çœŒ", "ä½è³€çœŒ", "é•·å´çœŒ", "ç†Šæœ¬çœŒ", "å¤§åˆ†çœŒ", "å®®å´çœŒ", "é¹¿å…å³¶çœŒ", "æ²–ç¸„çœŒ",
]
PREFECTURE_CODES: Dict[str, str] = {
    "åŒ—æµ·é“": "01", "é’æ£®çœŒ": "02", "å²©æ‰‹çœŒ": "03", "å®®åŸçœŒ": "04", "ç§‹ç”°çœŒ": "05",
    "å±±å½¢çœŒ": "06", "ç¦å³¶çœŒ": "07", "èŒ¨åŸçœŒ": "08", "æ ƒæœ¨çœŒ": "09", "ç¾¤é¦¬çœŒ": "10",
    "åŸ¼ç‰çœŒ": "11", "åƒè‘‰çœŒ": "12", "æ±äº¬éƒ½": "13", "ç¥å¥ˆå·çœŒ": "14", "æ–°æ½ŸçœŒ": "15",
    "å¯Œå±±çœŒ": "16", "çŸ³å·çœŒ": "17", "ç¦äº•çœŒ": "18", "å±±æ¢¨çœŒ": "19", "é•·é‡çœŒ": "20",
    "å²é˜œçœŒ": "21", "é™å²¡çœŒ": "22", "æ„›çŸ¥çœŒ": "23", "ä¸‰é‡çœŒ": "24", "æ»‹è³€çœŒ": "25",
    "äº¬éƒ½åºœ": "26", "å¤§é˜ªåºœ": "27", "å…µåº«çœŒ": "28", "å¥ˆè‰¯çœŒ": "29", "å’Œæ­Œå±±çœŒ": "30",
    "é³¥å–çœŒ": "31", "å³¶æ ¹çœŒ": "32", "å²¡å±±çœŒ": "33", "åºƒå³¶çœŒ": "34", "å±±å£çœŒ": "35",
    "å¾³å³¶çœŒ": "36", "é¦™å·çœŒ": "37", "æ„›åª›çœŒ": "38", "é«˜çŸ¥çœŒ": "39", "ç¦å²¡çœŒ": "40",
    "ä½è³€çœŒ": "41", "é•·å´çœŒ": "42", "ç†Šæœ¬çœŒ": "43", "å¤§åˆ†çœŒ": "44", "å®®å´çœŒ": "45",
    "é¹¿å…å³¶çœŒ": "46", "æ²–ç¸„çœŒ": "47",
}

# å…¨å›½çµ±è¨ˆï¼ˆåšç”ŸåŠ´åƒçœã€Œèª¿å‰¤åŒ»ç™‚è²»ã®å‹•å‘ã€2022å¹´åº¦ï¼‰
NATIONAL_STATS = {
    "total_prescriptions": 885_000_000,
    "total_pharmacies": 61_860,
    "average_per_year": 14_305,
    "median_estimate": 8_000,
    "daily_average": 44,
    "working_days": 305,
    "outpatient_rx_rate": 0.745,    # é™¢å¤–å‡¦æ–¹ç‡ï¼ˆå…¨å›½å¹³å‡ï¼‰
    "prescription_per_visit": 0.65,  # å¤–æ¥1å—è¨ºã‚ãŸã‚Šå‡¦æ–¹ç®‹ç™ºè¡Œç‡
    "source": "åšç”ŸåŠ´åƒçœã€Œèª¿å‰¤åŒ»ç™‚è²»ã®å‹•å‘ã€2022å¹´åº¦",
}

# è¨ºç™‚ç§‘åˆ¥ å‡¦æ–¹ç®‹ç™ºè¡Œç‡ï¼ˆå¤–æ¥æ‚£è€…1äººã‚ãŸã‚Šï¼‰
SPECIALTY_RX_RATES: Dict[str, Tuple[float, str]] = {
    "ä¸€èˆ¬å†…ç§‘":     (0.76, "å†…ç§‘ç³»å…¨èˆ¬ï¼ˆæ…¢æ€§ç–¾æ‚£ãŒå¤šãé«˜å‡¦æ–¹ç‡ï¼‰"),
    "å¾ªç’°å™¨å†…ç§‘":   (0.88, "é«˜è¡€åœ§ãƒ»å¿ƒç–¾æ‚£ã¯ç¶™ç¶šå‡¦æ–¹ãŒå¤šã„"),
    "æ¶ˆåŒ–å™¨å†…ç§‘":   (0.74, "èƒƒè…¸ç–¾æ‚£ã¯è–¬ç‰©ç™‚æ³•ãŒä¸»ä½“"),
    "ç³–å°¿ç—…å†…ç§‘":   (0.90, "ã‚¤ãƒ³ã‚¹ãƒªãƒ³ãƒ»çµŒå£è¡€ç³–é™ä¸‹è–¬ã®ç¶™ç¶šå‡¦æ–¹"),
    "ç¥çµŒå†…ç§‘":     (0.82, "ç¥çµŒç–¾æ‚£ã¯è–¬ç‰©ç™‚æ³•ä¾å­˜åº¦é«˜"),
    "å‘¼å¸å™¨å†…ç§‘":   (0.78, "å–˜æ¯ãƒ»COPDç­‰ã®ç¶™ç¶šè–¬å¤šã„"),
    "å¤–ç§‘":         (0.58, "è¡“å¾Œãƒ•ã‚©ãƒ­ãƒ¼ã®å‡¦æ–¹ã¯æ¯”è¼ƒçš„å°‘ãªã„"),
    "æ•´å½¢å¤–ç§‘":     (0.72, "é®ç—›è–¬ãƒ»æ¹¿å¸ƒç­‰ã®å‡¦æ–¹å¤šã„"),
    "çš®è†šç§‘":       (0.64, "å¤–ç”¨è–¬ãƒ»æŠ—ã‚¢ãƒ¬ãƒ«ã‚®ãƒ¼è–¬ãªã©"),
    "çœ¼ç§‘":         (0.52, "ç‚¹çœ¼è–¬ã¯é™¢å†…äº¤ä»˜ã‚‚å¤šã„"),
    "è€³é¼»å’½å–‰ç§‘":   (0.58, "æŠ—èŒè–¬ç­‰ã®çŸ­æœŸå‡¦æ–¹ãŒå¤šã„"),
    "ç²¾ç¥ç§‘":       (0.85, "å‘ç²¾ç¥è–¬ã¯ç¶™ç¶šå‡¦æ–¹ãŒã»ã¼å¿…é ˆ"),
    "å°å…ç§‘":       (0.62, "æ€¥æ€§ç–¾æ‚£ãŒå¤šãå‡¦æ–¹ã¯æ¯”è¼ƒçš„å°‘ãªã„"),
    "ç”£å©¦äººç§‘":     (0.44, "å¥è¨ºãƒ»åˆ†å¨©ãŒå¤šãè–¬å‡¦æ–¹ã¯å°‘ãªã„"),
    "æ³Œå°¿å™¨ç§‘":     (0.70, "å‰ç«‹è…ºç–¾æ‚£ãƒ»éæ´»å‹•è†€èƒ±ç­‰ã®ç¶™ç¶šè–¬"),
    "ãƒªãƒãƒ“ãƒªç§‘":   (0.40, "ãƒªãƒãƒ“ãƒªä¸­å¿ƒã§å‡¦æ–¹ã¯å°‘ãªã„"),
    "ä¸æ˜/ãã®ä»–":  (0.68, "å…¨è¨ºç™‚ç§‘å¹³å‡å€¤ã‚’ä½¿ç”¨"),
}

# OSM ã® healthcare:speciality ã‚¿ã‚° â†’ æ—¥æœ¬èªè¨ºç™‚ç§‘ãƒãƒƒãƒ”ãƒ³ã‚°
OSM_SPECIALTY_MAP: Dict[str, str] = {
    "general": "ä¸€èˆ¬å†…ç§‘", "general_practitioner": "ä¸€èˆ¬å†…ç§‘", "internal": "ä¸€èˆ¬å†…ç§‘",
    "cardiology": "å¾ªç’°å™¨å†…ç§‘",
    "gastroenterology": "æ¶ˆåŒ–å™¨å†…ç§‘",
    "diabetes": "ç³–å°¿ç—…å†…ç§‘", "endocrinology": "ç³–å°¿ç—…å†…ç§‘",
    "neurology": "ç¥çµŒå†…ç§‘",
    "pulmonology": "å‘¼å¸å™¨å†…ç§‘", "respiratory": "å‘¼å¸å™¨å†…ç§‘",
    "surgery": "å¤–ç§‘",
    "orthopaedics": "æ•´å½¢å¤–ç§‘", "orthopedics": "æ•´å½¢å¤–ç§‘",
    "dermatology": "çš®è†šç§‘",
    "ophthalmology": "çœ¼ç§‘",
    "otolaryngology": "è€³é¼»å’½å–‰ç§‘", "ent": "è€³é¼»å’½å–‰ç§‘",
    "psychiatry": "ç²¾ç¥ç§‘", "mental_health": "ç²¾ç¥ç§‘",
    "paediatrics": "å°å…ç§‘", "pediatrics": "å°å…ç§‘",
    "gynaecology": "ç”£å©¦äººç§‘", "obstetrics": "ç”£å©¦äººç§‘",
    "urology": "æ³Œå°¿å™¨ç§‘",
    "rehabilitation": "ãƒªãƒãƒ“ãƒªç§‘",
}

# å¹´é½¢å±¤åˆ¥ å¤–æ¥å—è¨ºç‡ï¼ˆå›/å¹´/äººï¼‰åšç”ŸåŠ´åƒçœã€Œæ‚£è€…èª¿æŸ»ã€2020å¹´
VISIT_RATE_BY_AGE: Dict[str, float] = {
    "0-14æ­³":  9.8,
    "15-44æ­³": 7.2,
    "45-64æ­³": 11.3,
    "65-74æ­³": 19.2,
    "75æ­³ä»¥ä¸Š": 22.1,
}

# æ—¥æœ¬ã®å¹´é½¢åˆ†å¸ƒï¼ˆ2020å¹´å›½å‹¢èª¿æŸ»ï¼‰
AGE_DISTRIBUTION: Dict[str, float] = {
    "0-14æ­³":  0.119,
    "15-44æ­³": 0.342,
    "45-64æ­³": 0.256,
    "65-74æ­³": 0.145,
    "75æ­³ä»¥ä¸Š": 0.138,
}

# å¤§æ‰‹ãƒã‚§ãƒ¼ãƒ³è–¬å±€ï¼ˆç«¶åˆåˆ¤å®šã«ä½¿ç”¨ï¼‰
MAJOR_CHAINS = [
    "ã‚¦ã‚¨ãƒ«ã‚·ã‚¢", "ãƒ„ãƒ«ãƒ", "ãƒãƒ„ãƒ¢ãƒˆã‚­ãƒ¨ã‚·", "ãƒãƒ„ã‚­ãƒ¨", "ã‚¹ã‚®è–¬å±€",
    "ã‚³ã‚¹ãƒ¢ã‚¹è–¬å“", "ã‚¯ãƒªã‚¨ã‚¤ãƒˆ", "ã‚µãƒ³ãƒ‰ãƒ©ãƒƒã‚°", "ã‚«ãƒ¯ãƒè–¬å“",
    "æ—¥æœ¬èª¿å‰¤", "ã‚¯ã‚ªãƒ¼ãƒ«", "ã‚¢ã‚¤ãƒ³", "ãƒ•ã‚¡ãƒ¼ãƒãƒ©ã‚¤ã‚º", "ç·åˆãƒ¡ãƒ‡ã‚£ã‚«ãƒ«",
]

# ---------------------------------------------------------------------------
# äººå£å¯†åº¦ãƒ«ãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆ2020å¹´å›½å‹¢èª¿æŸ»ãƒ™ãƒ¼ã‚¹ï¼‰
# ---------------------------------------------------------------------------

# æ±äº¬23åŒº äººå£å¯†åº¦ï¼ˆäºº/kmÂ²ï¼‰
TOKYO_WARD_DENSITY: Dict[str, int] = {
    "åƒä»£ç”°åŒº":  4073, "ä¸­å¤®åŒº":  13762, "æ¸¯åŒº":    10649, "æ–°å®¿åŒº":  18235,
    "æ–‡äº¬åŒº":   20105, "å°æ±åŒº":  19419, "å¢¨ç”°åŒº":  19508, "æ±Ÿæ±åŒº":  13943,
    "å“å·åŒº":   17617, "ç›®é»’åŒº":  18984, "å¤§ç”°åŒº":  12461, "ä¸–ç”°è°·åŒº": 16006,
    "æ¸‹è°·åŒº":   15608, "ä¸­é‡åŒº":  20539, "æ‰ä¸¦åŒº":  16524, "è±Šå³¶åŒº":  22449,
    "åŒ—åŒº":     17974, "è’å·åŒº":  21222, "æ¿æ©‹åŒº":  17598, "ç·´é¦¬åŒº":  14587,
    "è¶³ç«‹åŒº":   13752, "è‘›é£¾åŒº":  13802, "æ±Ÿæˆ¸å·åŒº": 13329,
}

# å¤§é˜ªå¸‚24åŒº äººå£å¯†åº¦ï¼ˆäºº/kmÂ²ï¼‰
OSAKA_WARD_DENSITY: Dict[str, int] = {
    "éƒ½å³¶åŒº":  13500, "ç¦å³¶åŒº":  11000, "æ­¤èŠ±åŒº":   6700, "è¥¿åŒº":   12500,
    "æ¸¯åŒº":    12000, "å¤§æ­£åŒº":  10500, "å¤©ç‹å¯ºåŒº": 15500, "æµªé€ŸåŒº":  15000,
    "è¥¿æ·€å·åŒº":  9500, "æ±æ·€å·åŒº": 17000, "æ±æˆåŒº":  19000, "ç”Ÿé‡åŒº":  18000,
    "æ—­åŒº":    15000, "åŸæ±åŒº":  18000, "é˜¿å€é‡åŒº": 15500, "ä½å‰åŒº":  14500,
    "æ±ä½å‰åŒº": 15500, "è¥¿æˆåŒº":  18000, "æ·€å·åŒº":  15500, "é¶´è¦‹åŒº":  12000,
    "ä½ä¹‹æ±ŸåŒº":  8500, "å¹³é‡åŒº":  13500, "åŒ—åŒº":     9500, "ä¸­å¤®åŒº":   7000,
}

# ä¸»è¦éƒ½å¸‚ äººå£å¯†åº¦ï¼ˆäºº/kmÂ²ï¼‰ â€” æ”¿ä»¤æŒ‡å®šéƒ½å¸‚ãƒ»ä¸»è¦å¸‚
CITY_DENSITY: Dict[str, int] = {
    # æ”¿ä»¤æŒ‡å®šéƒ½å¸‚
    "æœ­å¹Œå¸‚":    1882, "ä»™å°å¸‚":    1510, "ã•ã„ãŸã¾å¸‚": 5527, "åƒè‘‰å¸‚":    3625,
    "æ¨ªæµœå¸‚":    8717, "å·å´å¸‚":   10235, "ç›¸æ¨¡åŸå¸‚":   2716,
    "æ–°æ½Ÿå¸‚":    1100, "é™å²¡å¸‚":     496, "æµœæ¾å¸‚":      537,
    "åå¤å±‹å¸‚":  7138, "äº¬éƒ½å¸‚":    2804, "å¤§é˜ªå¸‚":    12110, "å ºå¸‚":     5219,
    "ç¥æˆ¸å¸‚":    2799, "å²¡å±±å¸‚":     942, "åºƒå³¶å¸‚":     1625, "åŒ—ä¹å·å¸‚":  1994,
    "ç¦å²¡å¸‚":    4990, "ç†Šæœ¬å¸‚":    1891,
    # ä¸»è¦å¸‚ï¼ˆäººå£20ä¸‡äººä»¥ä¸Šç­‰ï¼‰
    "æ—­å·å¸‚":     454, "å‡½é¤¨å¸‚":     566, "é’æ£®å¸‚":      753, "ç››å²¡å¸‚":     757,
    "ç§‹ç”°å¸‚":     629, "å±±å½¢å¸‚":     844, "ç¦å³¶å¸‚":      619, "éƒ¡å±±å¸‚":     768,
    "ã„ã‚ãå¸‚":   268, "æ°´æˆ¸å¸‚":    2122, "å®‡éƒ½å®®å¸‚":   1255, "å‰æ©‹å¸‚":     966,
    "é«˜å´å¸‚":    1062, "å·è¶Šå¸‚":    3017, "èˆ¹æ©‹å¸‚":     7068, "æŸå¸‚":      4022,
    "å…«ç‹å­å¸‚":  2584, "åºœä¸­å¸‚":    7029, "èª¿å¸ƒå¸‚":     8225, "ç”ºç”°å¸‚":    4965,
    "è—¤æ²¢å¸‚":    5046, "æ¨ªé ˆè³€å¸‚":  3665, "é•·é‡å¸‚":      648, "å²é˜œå¸‚":    2098,
    "è±Šæ©‹å¸‚":    2031, "è±Šç”°å¸‚":     989, "å²¡å´å¸‚":     1575, "ä¸€å®®å¸‚":    3030,
    "å¤§æ´¥å¸‚":    1070, "å¹ç”°å¸‚":   10267, "é«˜æ§»å¸‚":     4898, "æ±å¤§é˜ªå¸‚":  9267,
    "å§«è·¯å¸‚":    1150, "å°¼å´å¸‚":    8116, "è¥¿å®®å¸‚":     3796, "å¥ˆè‰¯å¸‚":    1087,
    "å’Œæ­Œå±±å¸‚":  2310, "å€‰æ•·å¸‚":     849, "ç¦å±±å¸‚":      953, "å‘‰å¸‚":       786,
    "ä¸‹é–¢å¸‚":     552, "é«˜æ¾å¸‚":    1583, "æ¾å±±å¸‚":     1140, "é«˜çŸ¥å¸‚":    1106,
    "ä¹…ç•™ç±³å¸‚":  2045, "é•·å´å¸‚":    1641, "ä½ä¸–ä¿å¸‚":    638, "å¤§åˆ†å¸‚":     861,
    "å®®å´å¸‚":     849, "é¹¿å…å³¶å¸‚":  1439, "é‚£è¦‡å¸‚":     8356,
    "å·å£å¸‚":    7230, "è¶Šè°·å¸‚":    5630, "è‰åŠ å¸‚":     8270, "æ˜¥æ—¥éƒ¨å¸‚":  2810,
    "æ¾æˆ¸å¸‚":    6230, "å¸‚å·å¸‚":    6610, "æµ¦å®‰å¸‚":    10490, "å¸‚åŸå¸‚":    1090,
    "æ‰€æ²¢å¸‚":    3640, "å¹³å¡šå¸‚":    3490, "åšæœ¨å¸‚":    2070, "å¤§å’Œå¸‚":    6610,
}

# éƒ½é“åºœçœŒå¹³å‡ äººå£å¯†åº¦ï¼ˆäºº/kmÂ²ï¼‰
PREFECTURE_DENSITY: Dict[str, int] = {
    "åŒ—æµ·é“":  64, "é’æ£®çœŒ": 130, "å²©æ‰‹çœŒ":  84, "å®®åŸçœŒ": 321, "ç§‹ç”°çœŒ":  86,
    "å±±å½¢çœŒ": 116, "ç¦å³¶çœŒ": 139, "èŒ¨åŸçœŒ": 476, "æ ƒæœ¨çœŒ": 307, "ç¾¤é¦¬çœŒ": 309,
    "åŸ¼ç‰çœŒ": 1927, "åƒè‘‰çœŒ": 1211, "æ±äº¬éƒ½": 6263, "ç¥å¥ˆå·çœŒ": 3810,
    "æ–°æ½ŸçœŒ": 179, "å¯Œå±±çœŒ": 247, "çŸ³å·çœŒ": 277, "ç¦äº•çœŒ": 189, "å±±æ¢¨çœŒ": 185,
    "é•·é‡çœŒ": 155, "å²é˜œçœŒ": 191, "é™å²¡çœŒ": 469, "æ„›çŸ¥çœŒ": 1457, "ä¸‰é‡çœŒ": 309,
    "æ»‹è³€çœŒ": 351, "äº¬éƒ½åºœ": 566, "å¤§é˜ªåºœ": 4631, "å…µåº«çœŒ": 652, "å¥ˆè‰¯çœŒ": 366,
    "å’Œæ­Œå±±çœŒ": 196, "é³¥å–çœŒ": 162, "å³¶æ ¹çœŒ": 103, "å²¡å±±çœŒ": 270, "åºƒå³¶çœŒ": 336,
    "å±±å£çœŒ": 224, "å¾³å³¶çœŒ": 184, "é¦™å·çœŒ": 519, "æ„›åª›çœŒ": 241, "é«˜çŸ¥çœŒ": 102,
    "ç¦å²¡çœŒ": 1023, "ä½è³€çœŒ": 340, "é•·å´çœŒ": 330, "ç†Šæœ¬çœŒ": 238, "å¤§åˆ†çœŒ": 182,
    "å®®å´çœŒ": 141, "é¹¿å…å³¶çœŒ": 179, "æ²–ç¸„çœŒ": 637,
}

# ---------------------------------------------------------------------------
# ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹
# ---------------------------------------------------------------------------

@dataclass
class PharmacyCandidate:
    name: str
    address: str
    href: str
    pref_cd: str = ""
    kikan_cd: str = ""

@dataclass
class NearbyFacility:
    name: str
    facility_type: str       # "hospital" | "clinic" | "pharmacy"
    lat: float
    lon: float
    distance_m: float        # å¯¾è±¡è–¬å±€ã‹ã‚‰ã®ç›´ç·šè·é›¢ï¼ˆmï¼‰
    specialty: str = "ä¸æ˜/ãã®ä»–"
    daily_outpatients: int = 0
    beds: int = 0
    has_inhouse_pharmacy: bool = False
    has_gate_pharmacy: bool = False
    osm_tags: Dict = field(default_factory=dict)
    mhlw_annual_outpatients: Optional[int] = None

@dataclass
class PredictionResult:
    method_name: str
    annual_rx: int
    min_val: int
    max_val: int
    confidence: str
    daily_rx: int
    breakdown: List[Dict] = field(default_factory=list)
    methodology: List[str] = field(default_factory=list)
    references: List[Dict] = field(default_factory=list)

@dataclass
class FullAnalysis:
    pharmacy_name: str
    pharmacy_address: str
    pharmacy_lat: float
    pharmacy_lon: float
    geocode_display: str          # Nominatim ãŒè¿”ã—ãŸæ­£è¦åŒ–ä½æ‰€
    mhlw_annual_rx: Optional[int]
    mhlw_source_url: str
    method1: Optional[PredictionResult]
    method2: Optional[PredictionResult]
    nearby_medical: List[NearbyFacility]
    nearby_pharmacies: List[NearbyFacility]
    # v2.1 è¿½åŠ : è‡ªå‹•è¨ˆç®—ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    area_density: int = 3000
    area_density_source: str = ""
    commercial_radius: int = 500
    commercial_radius_reason: str = ""
    is_gate_pharmacy: bool = False
    gate_pharmacy_reason: str = ""
    search_log: List[str] = field(default_factory=list)


# ---------------------------------------------------------------------------
# 1. äººå£å¯†åº¦ãƒ»å•†åœåŠå¾„ è‡ªå‹•è¨ˆç®—ï¼ˆv2.1 æ–°æ©Ÿèƒ½ï¼‰
# ---------------------------------------------------------------------------

def get_population_density(address: str) -> Tuple[int, str]:
    """
    ä½æ‰€æ–‡å­—åˆ—ã‹ã‚‰äººå£å¯†åº¦ï¼ˆäºº/kmÂ²ï¼‰ã‚’è‡ªå‹•æ¨å®šã™ã‚‹ã€‚
    ç²¾åº¦ã®é«˜ã„é †: æ±äº¬23åŒº â†’ å¤§é˜ª24åŒº â†’ ä¸»è¦å¸‚ â†’ éƒ½é“åºœçœŒå¹³å‡

    Returns:
        (density, source_description)
    """
    if not address:
        return 3000, "ä½æ‰€ä¸æ˜ï¼ˆä¸­é«˜å¯†åº¦ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ï¼‰"

    addr = address.strip()

    # â”€â”€ 1. æ±äº¬23åŒº
    if "æ±äº¬éƒ½" in addr:
        for ward, density in TOKYO_WARD_DENSITY.items():
            if ward in addr:
                return density, f"{ward}ï¼ˆæ±äº¬éƒ½ï¼‰ 2020å¹´å›½å‹¢èª¿æŸ»"
        # æ±äº¬éƒ½ã ãŒåŒºæœªç‰¹å®š
        return 6263, "æ±äº¬éƒ½å¹³å‡ï¼ˆåŒºæœªç‰¹å®šï¼‰ 2020å¹´å›½å‹¢èª¿æŸ»"

    # â”€â”€ 2. å¤§é˜ªå¸‚24åŒº
    if "å¤§é˜ªå¸‚" in addr:
        for ward, density in OSAKA_WARD_DENSITY.items():
            if ward in addr:
                return density, f"å¤§é˜ªå¸‚{ward} 2020å¹´å›½å‹¢èª¿æŸ»"
        return 12110, "å¤§é˜ªå¸‚å¹³å‡ï¼ˆåŒºæœªç‰¹å®šï¼‰ 2020å¹´å›½å‹¢èª¿æŸ»"

    # â”€â”€ 3. ä¸»è¦å¸‚ï¼ˆæ”¿ä»¤æŒ‡å®šéƒ½å¸‚ãƒ»ä¸»è¦å¸‚ï¼‰
    for city, density in CITY_DENSITY.items():
        if city in addr:
            return density, f"{city} å¹³å‡äººå£å¯†åº¦ 2020å¹´å›½å‹¢èª¿æŸ»"

    # â”€â”€ 4. éƒ½é“åºœçœŒãƒ¬ãƒ™ãƒ«
    for pref, density in PREFECTURE_DENSITY.items():
        if pref in addr:
            return density, f"{pref} å¹³å‡äººå£å¯†åº¦ 2020å¹´å›½å‹¢èª¿æŸ»"

    # â”€â”€ 5. ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    return 1500, "ä½æ‰€è§£æä¸èƒ½ï¼ˆä¸­å¯†åº¦ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ 1,500äºº/kmÂ²ï¼‰"


def detect_gate_pharmacy(
    pharmacy_name: str,
    nearby_medical: List[NearbyFacility],
) -> Tuple[bool, str]:
    """
    é–€å‰è–¬å±€ã‹ã©ã†ã‹ã‚’åˆ¤å®šã™ã‚‹ã€‚

    åˆ¤å®šåŸºæº–:
      â‘  è–¬å±€åã«ã€Œé–€å‰ã€ã€Œç—…é™¢å‰ã€ã€ŒåŒ»é™¢å‰ã€ã€Œã‚¯ãƒªãƒ‹ãƒƒã‚¯å‰ã€ãŒå«ã¾ã‚Œã‚‹
      â‘¡ 80mä»¥å†…ã«åŒ»ç™‚æ©Ÿé–¢ãŒå­˜åœ¨ã™ã‚‹
      â‘¢ è¿‘éš£åŒ»ç™‚æ©Ÿé–¢ã®åç§°ï¼ˆå…ˆé ­4æ–‡å­—ï¼‰ãŒè–¬å±€åã«å«ã¾ã‚Œã‚‹

    Returns:
        (is_gate, reason)
    """
    # â‘  åç§°ãƒã‚§ãƒƒã‚¯
    gate_keywords = ["é–€å‰", "ç—…é™¢å‰", "åŒ»é™¢å‰", "ã‚¯ãƒªãƒ‹ãƒƒã‚¯å‰", "é™¢å‰"]
    for kw in gate_keywords:
        if kw in pharmacy_name:
            return True, f"è–¬å±€åã«ã€Œ{kw}ã€ãŒå«ã¾ã‚Œã‚‹"

    # â‘¡ 80mä»¥å†…ã«åŒ»ç™‚æ©Ÿé–¢
    if nearby_medical:
        for fac in sorted(nearby_medical, key=lambda f: f.distance_m):
            if fac.distance_m <= 80:
                return True, f"ã€Œ{fac.name}ã€({fac.distance_m:.0f}mä»¥å†…)ã«éš£æ¥ã™ã‚‹é–€å‰ç«‹åœ°"

        # â‘¢ æ–½è¨­åãŒè–¬å±€åã«å«ã¾ã‚Œã‚‹ï¼ˆ4æ–‡å­—ä»¥ä¸Šä¸€è‡´ï¼‰
        for fac in nearby_medical[:5]:
            short = fac.name[:4]
            if len(short) >= 4 and short in pharmacy_name:
                return True, f"ã€Œ{fac.name}ã€ã®åç§°ãŒè–¬å±€åã«å«ã¾ã‚Œã‚‹ï¼ˆé–€å‰ã¨æ¨å®šï¼‰"

    return False, "é€šå¸¸å•†åœå‹ï¼ˆé–€å‰åˆ¤å®šãªã—ï¼‰"


def calc_commercial_radius(
    density: int,
    is_gate: bool = False,
    gate_reason: str = "",
) -> Tuple[int, str]:
    """
    äººå£å¯†åº¦ã¨é–€å‰åˆ¤å®šã‹ã‚‰å•†åœåŠå¾„ï¼ˆmï¼‰ã‚’ç®—å‡ºã™ã‚‹ã€‚

    é–€å‰è–¬å±€: åŒ»ç™‚æ©Ÿé–¢ä¾å­˜å‹ã®ãŸã‚300må›ºå®š
    é€šå¸¸è–¬å±€: äººå£å¯†åº¦ã«åŸºã¥ãæ®µéšçš„è¨­å®š

    Returns:
        (radius_m, reason)
    """
    if is_gate:
        return 300, f"é–€å‰è–¬å±€ï¼ˆ{gate_reason}ï¼‰â†’ åŒ»ç™‚æ©Ÿé–¢ä¾å­˜å‹ã®ãŸã‚300må›ºå®š"

    if density >= 12_000:
        r, note = 300,  "è¶…é«˜å¯†åº¦åœ°åŸŸï¼ˆ12,000äºº/kmÂ²ä»¥ä¸Šï¼‰å¾’æ­©5åˆ†åœ"
    elif density >= 6_000:
        r, note = 400,  "é«˜å¯†åº¦åœ°åŸŸï¼ˆ6,000ã€œ12,000äºº/kmÂ²ï¼‰å¾’æ­©7åˆ†åœ"
    elif density >= 3_000:
        r, note = 500,  "ä¸­é«˜å¯†åº¦åœ°åŸŸï¼ˆ3,000ã€œ6,000äºº/kmÂ²ï¼‰å¾’æ­©8åˆ†åœ"
    elif density >= 1_500:
        r, note = 700,  "ä¸­å¯†åº¦åœ°åŸŸï¼ˆ1,500ã€œ3,000äºº/kmÂ²ï¼‰å¾’æ­©12åˆ†åœ"
    elif density >= 500:
        r, note = 1000, "ä½å¯†åº¦åœ°åŸŸï¼ˆ500ã€œ1,500äºº/kmÂ²ï¼‰å¾’æ­©ãƒ»è‡ªè»¢è»Šåœ"
    else:
        r, note = 2000, "è¶…ä½å¯†åº¦åœ°åŸŸï¼ˆ500äºº/kmÂ²æœªæº€ï¼‰åºƒåŸŸå•†åœ"

    return r, f"{note}ï¼ˆå¯†åº¦: {density:,}äºº/kmÂ²ï¼‰"


# ---------------------------------------------------------------------------
# 2. ã‚¸ã‚ªã‚³ãƒ¼ãƒ€ãƒ¼ï¼ˆNominatim / OpenStreetMapï¼‰â€” v2.1 ä¿®æ­£ç‰ˆ
# ---------------------------------------------------------------------------

class GeocoderService:
    """
    ä½æ‰€ â†’ ç·¯åº¦çµŒåº¦å¤‰æ›ï¼ˆNominatim APIã‚’ä½¿ç”¨ãƒ»ç„¡æ–™ãƒ»APIã‚­ãƒ¼ä¸è¦ï¼‰

    v2.1 ä¿®æ­£:
      - User-Agent ã‹ã‚‰æ‹¬å¼§ã‚’é™¤å»ï¼ˆVarnish 403 å¯¾ç­–ï¼‰
      - å…¨è§’æ–‡å­—å¤‰æ›ãƒã‚°ä¿®æ­£ï¼ˆå…¨è§’ã‚¹ãƒšãƒ¼ã‚¹ã‚’åˆ¥é€”å¤‰æ›ï¼‰
      - ãƒ—ãƒ­ã‚°ãƒ¬ãƒƒã‚·ãƒ–ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆæœ€å¤§5ãƒãƒªã‚¢ãƒ³ãƒˆè©¦è¡Œï¼‰
      - åº§æ¨™ã‚µãƒ‹ãƒ†ã‚£ãƒã‚§ãƒƒã‚¯ï¼ˆæ—¥æœ¬å›½å†…ã®ç¯„å›²ã«é™å®šï¼‰
    """

    URL = "https://nominatim.openstreetmap.org/search"
    # æ—¥æœ¬ã®åº§æ¨™ç¯„å›²
    LAT_MIN, LAT_MAX = 24.0, 46.0
    LON_MIN, LON_MAX = 122.0, 154.0

    def _to_halfwidth(self, text: str) -> str:
        """å…¨è§’æ•°å­—ãƒ»ãƒã‚¤ãƒ•ãƒ³ã‚’åŠè§’ã«å¤‰æ›"""
        trans = str.maketrans("ï¼ï¼‘ï¼’ï¼“ï¼”ï¼•ï¼–ï¼—ï¼˜ï¼™ï¼", "0123456789-")
        result = text.translate(trans)
        result = result.replace("ã€€", " ")  # å…¨è§’ã‚¹ãƒšãƒ¼ã‚¹ã¯åˆ¥é€”å¤‰æ›
        return result

    def _is_japan(self, lat: float, lon: float) -> bool:
        """åº§æ¨™ãŒæ—¥æœ¬å›½å†…ã‹ãƒã‚§ãƒƒã‚¯"""
        return (self.LAT_MIN <= lat <= self.LAT_MAX and
                self.LON_MIN <= lon <= self.LON_MAX)

    def _build_fallback_variants(self, address: str) -> List[str]:
        """ãƒ—ãƒ­ã‚°ãƒ¬ãƒƒã‚·ãƒ–ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ã®ä½æ‰€ãƒãƒªã‚¢ãƒ³ãƒˆã‚’ç”Ÿæˆ"""
        variants: List[str] = []

        # 1. ãƒ•ãƒ«ä½æ‰€
        variants.append(address + " æ—¥æœ¬")

        # 2. å»ºç‰©åãƒ»ç•ªå·ã‚’é™¤å»ã—ãŸçŸ­ç¸®ä½æ‰€
        short = re.sub(r"\d+(?:éš|F|æ£Ÿ|å·å®¤|å·).*$", "", address).strip()
        if short and short != address:
            v = short + " æ—¥æœ¬"
            if v not in variants:
                variants.append(v)

        # 3. ã‚¹ãƒšãƒ¼ã‚¹åŒºåˆ‡ã‚Šã§å‰ã‹ã‚‰Nå€‹
        parts = address.split()
        for n in [4, 3]:
            if len(parts) > n:
                v = " ".join(parts[:n]) + " æ—¥æœ¬"
                if v not in variants:
                    variants.append(v)

        # 4. éƒ½é“åºœçœŒ + å¸‚åŒºç”ºæ‘ã®ã¿
        pref_city_m = re.match(
            r"((?:æ±äº¬éƒ½|å¤§é˜ªåºœ|äº¬éƒ½åºœ|åŒ—æµ·é“)|.+?[éƒ½é“åºœçœŒ])(.+?[å¸‚åŒºç”ºæ‘])",
            address
        )
        if pref_city_m:
            v = pref_city_m.group(1) + pref_city_m.group(2) + " æ—¥æœ¬"
            if v not in variants:
                variants.append(v)

        return variants[:6]  # æœ€å¤§6ãƒãƒªã‚¢ãƒ³ãƒˆ

    def _try_nominatim(self, query: str, headers: Dict) -> Optional[Tuple[float, float, str]]:
        """Nominatim ã«1å›ã‚¯ã‚¨ãƒªã‚’è©¦ã¿ã‚‹"""
        try:
            params = {"q": query, "format": "json", "limit": 1}
            r = requests.get(self.URL, params=params, headers=headers, timeout=10)
            if r.status_code == 403:
                return None
            r.raise_for_status()
            data = r.json()
            if data:
                lat = float(data[0]["lat"])
                lon = float(data[0]["lon"])
                display = data[0].get("display_name", query)
                return lat, lon, display
        except Exception:
            pass
        return None

    def geocode(self, address: str) -> Tuple[Optional[float], Optional[float], str]:
        """
        ä½æ‰€ã‚’ç·¯åº¦çµŒåº¦ã«å¤‰æ›ã™ã‚‹ã€‚

        Returns:
            (lat, lon, status_message)
        """
        if not address:
            return None, None, "ä½æ‰€ãŒç©ºã§ã™"

        # ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
        clean = re.sub(r"Googleãƒãƒƒãƒ—.*|Google Map.*", "", address).strip()
        clean = self._to_halfwidth(clean)
        clean = re.sub(r"ã€’\s*\d{3}[-âˆ’]\d{4}\s*", "", clean).strip()
        clean = re.sub(r"\s+", " ", clean).strip()

        # User-Agent ã¯æ‹¬å¼§ãªã—ï¼ˆæ‹¬å¼§ãŒã‚ã‚‹ã¨ Nominatim ãŒ 403 ã‚’è¿”ã™ï¼‰
        headers = {"User-Agent": "PharmacyRxPredictor"}

        variants = self._build_fallback_variants(clean)

        for i, variant in enumerate(variants):
            if i > 0:
                time.sleep(1.1)  # Nominatim åˆ©ç”¨è¦ç´„: 1ç§’ä»¥ä¸Šã®é–“éš”
            result = self._try_nominatim(variant, headers)
            if result:
                lat, lon, display = result
                if self._is_japan(lat, lon):
                    short_query = variant.replace(" æ—¥æœ¬", "")
                    suffix = f"ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: {short_query}ï¼‰" if i > 0 else ""
                    return lat, lon, f"ç·¯åº¦: {lat:.5f}, çµŒåº¦: {lon:.5f}{suffix}"

        return None, None, f"åº§æ¨™å–å¾—å¤±æ•—ï¼ˆ{len(variants)}ãƒãƒªã‚¢ãƒ³ãƒˆè©¦è¡Œæ¸ˆã¿ï¼‰: {clean[:40]}"


# ---------------------------------------------------------------------------
# 3. è¿‘éš£æ–½è¨­æ¤œç´¢ï¼ˆOverpass API / OpenStreetMapï¼‰
# ---------------------------------------------------------------------------

class OverpassSearcher:
    """OpenStreetMap ã® Overpass API ã§è¿‘éš£åŒ»ç™‚æ–½è¨­ãƒ»è–¬å±€ã‚’æ¤œç´¢ï¼ˆç„¡æ–™ãƒ»APIã‚­ãƒ¼ä¸è¦ï¼‰"""

    URL = "https://overpass-api.de/api/interpreter"

    def search_nearby(
        self, lat: float, lon: float, radius: int = 600
    ) -> Tuple[List[NearbyFacility], List[NearbyFacility], str]:
        """
        æŒ‡å®šåº§æ¨™ã®åŠå¾„radius(m)å†…ã®åŒ»ç™‚æ–½è¨­ã¨è–¬å±€ã‚’å–å¾—ã™ã‚‹ã€‚

        Returns:
            (medical_facilities, pharmacies, status_message)
        """
        query = f"""
[out:json][timeout:30];
(
  node["amenity"~"^(hospital|clinic|doctors)$"](around:{radius},{lat},{lon});
  way["amenity"~"^(hospital|clinic|doctors)$"](around:{radius},{lat},{lon});
  node["healthcare"~"^(hospital|clinic|doctor|centre)$"](around:{radius},{lat},{lon});
  way["healthcare"~"^(hospital|clinic|doctor|centre)$"](around:{radius},{lat},{lon});
  node["amenity"="pharmacy"](around:{radius},{lat},{lon});
  way["amenity"="pharmacy"](around:{radius},{lat},{lon});
);
out center tags;
"""
        try:
            r = requests.post(self.URL, data={"data": query}, timeout=30)
            r.raise_for_status()
            data = r.json()
        except requests.Timeout:
            return [], [], "Overpass APIã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼ˆ30ç§’ï¼‰"
        except Exception as e:
            return [], [], f"Overpass APIã‚¨ãƒ©ãƒ¼: {e}"

        medical: List[NearbyFacility] = []
        pharmacies: List[NearbyFacility] = []

        for elem in data.get("elements", []):
            tags = elem.get("tags", {})
            name = tags.get("name", tags.get("name:ja", "åç§°ä¸æ˜"))
            if not name or name == "åç§°ä¸æ˜":
                continue

            if elem["type"] == "node":
                e_lat, e_lon = elem.get("lat", 0), elem.get("lon", 0)
            else:
                center = elem.get("center", {})
                e_lat, e_lon = center.get("lat", 0), center.get("lon", 0)

            if not (e_lat and e_lon):
                continue

            dist = self._haversine(lat, lon, e_lat, e_lon)
            amenity = tags.get("amenity", "")
            is_pharmacy = amenity == "pharmacy"

            if is_pharmacy:
                pharmacies.append(NearbyFacility(
                    name=name, facility_type="pharmacy",
                    lat=e_lat, lon=e_lon, distance_m=dist, osm_tags=tags,
                ))
                continue

            ftype = "hospital" if (
                amenity == "hospital"
                or tags.get("healthcare", "") == "hospital"
                or int(tags.get("beds", 0) or 0) >= 20
            ) else "clinic"

            specialty_raw = tags.get("healthcare:speciality", tags.get("specialty", ""))
            specialty = OSM_SPECIALTY_MAP.get(specialty_raw.lower(), "ä¸€èˆ¬å†…ç§‘") if specialty_raw else "ä¸€èˆ¬å†…ç§‘"
            has_inhouse = tags.get("pharmacy", "") in ["yes", "dispensing"]
            beds = int(tags.get("beds", 0) or 0)
            daily_op = self._estimate_daily_outpatients(ftype, beds, tags)

            medical.append(NearbyFacility(
                name=name, facility_type=ftype,
                lat=e_lat, lon=e_lon, distance_m=dist,
                specialty=specialty, daily_outpatients=daily_op,
                beds=beds, has_inhouse_pharmacy=has_inhouse, osm_tags=tags,
            ))

        medical.sort(key=lambda x: x.distance_m)
        pharmacies.sort(key=lambda x: x.distance_m)

        return medical, pharmacies, f"åŒ»ç™‚æ©Ÿé–¢{len(medical)}ä»¶ãƒ»è–¬å±€{len(pharmacies)}ä»¶ã‚’å–å¾—"

    @staticmethod
    def _haversine(lat1: float, lon1: float, lat2: float, lon2: float) -> float:
        R = 6_371_000
        phi1, phi2 = math.radians(lat1), math.radians(lat2)
        dphi = math.radians(lat2 - lat1)
        dlam = math.radians(lon2 - lon1)
        a = math.sin(dphi / 2) ** 2 + math.cos(phi1) * math.cos(phi2) * math.sin(dlam / 2) ** 2
        return R * 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))

    @staticmethod
    def _estimate_daily_outpatients(ftype: str, beds: int, tags: Dict) -> int:
        if ftype == "hospital":
            if beds >= 300: return 1_000
            if beds >= 100: return 400
            return 150
        else:
            doctors = int(tags.get("staff:count", 0) or 0)
            if doctors >= 3: return 100
            if doctors >= 2: return 60
            return 35


# ---------------------------------------------------------------------------
# 4. åšç”ŸåŠ´åƒçœã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼
# ---------------------------------------------------------------------------

class MHLWScraper:
    """åšç”ŸåŠ´åƒçœ åŒ»ç™‚æƒ…å ±ãƒãƒƒãƒˆï¼ˆãƒŠãƒ“ã‚¤ï¼‰ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼"""

    DOMAIN = "https://www.iryou.teikyouseido.mhlw.go.jp"
    BASE   = DOMAIN + "/znk-web"

    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            "User-Agent": (
                "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) "
                "AppleWebKit/537.36 Chrome/121.0.0.0 Safari/537.36"
            ),
            "Accept-Language": "ja-JP,ja;q=0.9",
        })
        self._initialized = False

    def initialize_session(self) -> bool:
        try:
            r = self.session.get(
                f"{self.BASE}/juminkanja/S2300/initialize",
                timeout=15, allow_redirects=True,
            )
            self._initialized = r.status_code == 200
            return self._initialized
        except Exception:
            return False

    def search_pharmacy_candidates(
        self, keyword: str, pref_code: str = "", max_pages: int = 3
    ) -> Tuple[List[PharmacyCandidate], int, str]:
        return self._search_candidates(keyword, pref_code, max_pages, sjk="2")

    def search_medical_candidates(
        self, keyword: str, pref_code: str = ""
    ) -> Tuple[List[PharmacyCandidate], int, str]:
        return self._search_candidates(keyword, pref_code, max_pages=1, sjk="1")

    def _search_candidates(
        self, keyword: str, pref_code: str, max_pages: int, sjk: str
    ) -> Tuple[List[PharmacyCandidate], int, str]:
        if not self._initialized:
            self.initialize_session()

        try:
            r = self.session.get(
                f"{self.BASE}/juminkanja/S2300/yakkyokuSearch",
                params={"yakkyokuKeyword": keyword, "yakkyokuKeyword2": "", "searchJudgeKbn": "2"},
                headers={"ajaxFlag": "true"}, timeout=12,
            )
            if r.status_code != 200:
                return [], 0, f"æ¤œç´¢å¤±æ•— HTTP {r.status_code}"
            j = r.json()
            if j.get("code") != "0":
                return [], 0, "æ¤œç´¢ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³å¤±æ•—"
        except Exception as e:
            return [], 0, f"æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}"

        all_candidates: List[PharmacyCandidate] = []
        total_count = 0
        encoded = urllib.parse.quote(keyword)

        for page in range(max_pages):
            params = {"sjk": sjk, "page": str(page), "size": "20", "sortNo": "1"}
            if pref_code:
                params["prefCd"] = pref_code
            try:
                r2 = self.session.get(
                    f"{self.BASE}/juminkanja/S2400/initialize/{encoded}/",
                    params=params, timeout=15,
                )
                if r2.status_code != 200:
                    break
                candidates, total = self._parse_candidate_list(r2.text)
                if page == 0:
                    total_count = total
                all_candidates.extend(candidates)
                if len(candidates) == 0 or len(all_candidates) >= total_count:
                    break
                time.sleep(0.3)
            except Exception:
                break

        return all_candidates, total_count, f"{len(all_candidates)}ä»¶å–å¾—ï¼ˆå…¨{total_count}ä»¶ï¼‰"

    def _parse_candidate_list(
        self, html: str
    ) -> Tuple[List[PharmacyCandidate], int]:
        soup = BeautifulSoup(html, "html.parser")
        candidates = []
        total = 0
        cnt_match = re.search(r"(\d{1,6})\s*ä»¶", soup.get_text())
        if cnt_match:
            total = int(cnt_match.group(1))

        for item in soup.find_all("div", class_="item"):
            h3 = item.find("h3", class_="name")
            if not h3:
                continue
            link = h3.find("a", href=True)
            if not link:
                continue
            name = link.get_text(strip=True)
            href = link.get("href", "")
            if not href:
                continue
            if href.startswith("/"):
                href = self.DOMAIN + href

            parsed = urllib.parse.urlparse(href)
            qp = dict(urllib.parse.parse_qsl(parsed.query))
            pref_cd = qp.get("prefCd", "")
            kikan_cd = qp.get("kikanCd", "")

            address = ""
            for dl in item.find_all("dl"):
                dt = dl.find("dt")
                if not dt:
                    continue
                img = dt.find("img")
                dt_text = dt.get_text(strip=True)
                if (img and "ä½æ‰€" in img.get("alt", "")) or any(
                    kw in dt_text for kw in ["ä½æ‰€", "æ‰€åœ¨åœ°"]
                ):
                    dd = dl.find("dd")
                    if dd:
                        for a in dd.find_all("a"):
                            a.decompose()
                        raw = dd.get_text(strip=True)
                        cleaned = re.sub(r"ã€’\s*\d{3}[-ï¼]\d{4}\s*", "", raw)
                        address = re.sub(r"\s+", " ", cleaned).strip()[:60]
                    break

            if name:
                candidates.append(PharmacyCandidate(
                    name=name, address=address, href=href,
                    pref_cd=pref_cd, kikan_cd=kikan_cd,
                ))

        return candidates, max(total, len(candidates))

    def get_pharmacy_detail(
        self, candidate: PharmacyCandidate
    ) -> Tuple[Optional[Dict], str]:
        if not self._initialized:
            self.initialize_session()

        if candidate.pref_cd and candidate.kikan_cd:
            url = (
                f"{self.BASE}/juminkanja/S2430/initialize"
                f"?prefCd={candidate.pref_cd}&kikanCd={candidate.kikan_cd}&kikanKbn=5"
            )
        else:
            url = candidate.href

        try:
            r = self.session.get(url, timeout=15)
            if r.status_code != 200:
                return None, f"HTTP {r.status_code}"
            data = self._parse_pharmacy_detail(r.text)
            data["source_url"] = url
            return data, "OK"
        except Exception as e:
            return None, str(e)

    def _parse_pharmacy_detail(self, html: str) -> Dict:
        soup = BeautifulSoup(html, "html.parser")
        data: Dict = {}
        fields: Dict[str, str] = {}

        for row in soup.find_all("tr"):
            cells = row.find_all(["th", "td"])
            if len(cells) >= 2:
                key = cells[0].get_text(strip=True)
                val = cells[1].get_text(strip=True)
                if key:
                    fields[key] = val

        for dl in soup.find_all("dl"):
            dts = dl.find_all("dt")
            dds = dl.find_all("dd")
            for dt, dd in zip(dts, dds):
                key = dt.get_text(strip=True)
                val = dd.get_text(strip=True)
                if key:
                    fields[key] = val

        data["all_fields"] = fields

        for k, v in fields.items():
            if "æ‰€åœ¨åœ°" in k and "ãƒ•ãƒªã‚¬ãƒŠ" not in k and "è‹±èª" not in k:
                clean = re.sub(r"Googleãƒãƒƒãƒ—.*", "", v).strip()
                data["address"] = clean
                break

        rx_annual = None
        rx_period = None
        for field_key, field_val in fields.items():
            if "ç·å–æ‰±å‡¦æ–¹ç®‹æ•°" in field_key:
                nums = re.findall(r"[\d,]+", field_val)
                if nums:
                    try:
                        n = int(nums[0].replace(",", ""))
                        if n > 0:
                            rx_annual = n
                            rx_period = "å¹´é–“å®Ÿç¸¾ï¼ˆå‰å¹´1å¹´é–“ã®å–æ‰±å‡¦æ–¹ç®‹æšæ•°ï¼‰"
                            break
                    except (ValueError, OverflowError):
                        pass

        if rx_annual is None:
            full_text = soup.get_text(separator=" ")
            for pat, period, mult in [
                (r"ç·å–æ‰±å‡¦æ–¹ç®‹æ•°[^\d]*(\d{1,3}(?:,\d{3})*|\d{4,})\s*ä»¶", "annual", 1.0),
                (r"é€±\s*å¹³å‡[^\d]{0,15}(\d{1,4})\s*(?:å›|æš)", "weekly", 52.14),
                (r"å¹´é–“[^\d]{0,15}(\d{1,6}(?:,\d{3})*)\s*(?:å›|ä»¶)", "annual", 1.0),
            ]:
                m = re.search(pat, full_text, re.DOTALL)
                if m:
                    try:
                        n = int(m.group(1).replace(",", ""))
                        if n > 0:
                            rx_annual = int(n * mult)
                            rx_period = "é€±å¹³å‡â†’å¹´æ›ç®—" if period == "weekly" else "å¹´é–“å®Ÿç¸¾"
                            break
                    except (ValueError, OverflowError):
                        pass

        data["prescriptions_annual"] = rx_annual
        data["prescription_period_label"] = rx_period
        return data

    def get_medical_outpatient_data(
        self, facility_name: str, pref_code: str = ""
    ) -> Optional[int]:
        if not self._initialized:
            self.initialize_session()
        candidates, _, _ = self.search_medical_candidates(facility_name, pref_code)
        if not candidates:
            return None

        best = None
        for c in candidates[:3]:
            if facility_name[:4] in c.name or c.name[:4] in facility_name:
                best = c
                break
        if best is None and candidates:
            best = candidates[0]

        try:
            r = self.session.get(best.href, timeout=12)
            if r.status_code != 200:
                return None
            soup = BeautifulSoup(r.text, "html.parser")
            fields: Dict[str, str] = {}
            for row in soup.find_all("tr"):
                cells = row.find_all(["th", "td"])
                if len(cells) >= 2:
                    fields[cells[0].get_text(strip=True)] = cells[1].get_text(strip=True)
            for k, v in fields.items():
                if "å¤–æ¥" in k and ("æ‚£è€…" in k or "æ•°" in k):
                    nums = re.findall(r"[\d,]+", v)
                    if nums:
                        return int(nums[0].replace(",", ""))
        except Exception:
            pass
        return None


# ---------------------------------------------------------------------------
# 5. æ–¹æ³•â‘  è¿‘éš£åŒ»ç™‚æ©Ÿé–¢ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ
# ---------------------------------------------------------------------------

class Method1Predictor:
    OUTPATIENT_RX_RATE = NATIONAL_STATS["outpatient_rx_rate"]

    def predict(
        self,
        pharmacy_lat: float,
        pharmacy_lon: float,
        medical_facilities: List[NearbyFacility],
        competing_pharmacies: List[NearbyFacility],
    ) -> PredictionResult:
        breakdown = []
        total_daily_rx = 0.0
        methodology = [
            "### æ–¹æ³•â‘  ãƒ­ã‚¸ãƒƒã‚¯: è¿‘éš£åŒ»ç™‚æ©Ÿé–¢ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ",
            "",
            "**ç®—å‡ºå¼**:",
            "ã€€å„æ–½è¨­ã®å¤–æ¥æ‚£è€…æ•° Ã— è¨ºç™‚ç§‘åˆ¥å‡¦æ–¹ç®‹ç™ºè¡Œç‡",
            "ã€€Ã— é™¢å¤–å‡¦æ–¹ç‡ï¼ˆ0.745ï¼‰Ã— å½“è–¬å±€é›†å®¢ã‚·ã‚§ã‚¢",
            "ã€€â†’ æ–½è¨­ã”ã¨ã®å½“è–¬å±€ã¸ã®æ—¥æ¬¡æµå…¥å‡¦æ–¹ç®‹æ•°ã‚’åˆè¨ˆ",
            "",
            f"**å¯¾è±¡åŠå¾„**: æ¤œç´¢åŠå¾„å†…ã®åŒ»ç™‚æ–½è¨­ {len(medical_facilities)}ä»¶",
            "",
        ]

        for fac in medical_facilities:
            if fac.daily_outpatients == 0:
                continue
            rx_rate, _ = SPECIALTY_RX_RATES.get(fac.specialty, SPECIALTY_RX_RATES["ä¸æ˜/ãã®ä»–"])
            daily_outpatient_rx = fac.daily_outpatients * rx_rate * self.OUTPATIENT_RX_RATE
            if fac.has_inhouse_pharmacy:
                daily_outpatient_rx *= 0.6
            share, share_reason = self._calc_pharmacy_share(
                fac, pharmacy_lat, pharmacy_lon, competing_pharmacies
            )
            if fac.has_gate_pharmacy:
                share *= 0.4
                share_reason += "ï¼ˆæ—¢å­˜é–€å‰è–¬å±€ã‚ã‚Š â†’ ã‚·ã‚§ã‚¢å¤§å¹…å‰²å¼•ï¼‰"
            daily_flow = daily_outpatient_rx * share

            breakdown.append({
                "æ–½è¨­å":         fac.name,
                "ã‚¿ã‚¤ãƒ—":         "ç—…é™¢" if fac.facility_type == "hospital" else "ã‚¯ãƒªãƒ‹ãƒƒã‚¯",
                "è·é›¢":           f"{fac.distance_m:.0f}m",
                "è¨ºç™‚ç§‘":         fac.specialty,
                "å¤–æ¥æ‚£è€…/æ—¥":    fac.daily_outpatients,
                "å‡¦æ–¹ç®‹ç™ºè¡Œç‡":   f"{rx_rate:.0%}",
                "é™¢å¤–å‡¦æ–¹ç®‹/æ—¥":  round(daily_outpatient_rx),
                "å½“è–¬å±€ã‚·ã‚§ã‚¢":   f"{share:.1%}",
                "ã‚·ã‚§ã‚¢æ ¹æ‹ ":     share_reason,
                "å½“è–¬å±€æµå…¥/æ—¥":  round(daily_flow),
            })
            total_daily_rx += daily_flow
            methodology.append(
                f"**{fac.name}** ({fac.distance_m:.0f}m): "
                f"å¤–æ¥{fac.daily_outpatients}äºº/æ—¥ Ã— {rx_rate:.0%} Ã— é™¢å¤–ç‡{self.OUTPATIENT_RX_RATE:.1%} "
                f"Ã— å½“è–¬å±€{share:.0%} = {daily_flow:.1f}æš/æ—¥"
            )

        annual_est = int(total_daily_rx * NATIONAL_STATS["working_days"])
        min_val = int(annual_est * 0.6)
        max_val = int(annual_est * 1.8)

        methodology += [
            "",
            f"**åˆè¨ˆ**: {total_daily_rx:.1f}æš/æ—¥ Ã— {NATIONAL_STATS['working_days']}æ—¥ = **{annual_est:,}æš/å¹´**",
        ]

        if not medical_facilities:
            methodology.append("  âš  è¿‘éš£ã«åŒ»ç™‚æ–½è¨­ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚çµ±è¨ˆæ¨è¨ˆå€¤ã«ç½®ãæ›ãˆã¾ã™ã€‚")
            annual_est = NATIONAL_STATS["median_estimate"]
            min_val, max_val = 2_000, 20_000

        return PredictionResult(
            method_name="æ–¹æ³•â‘ : è¿‘éš£åŒ»ç™‚æ©Ÿé–¢ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ",
            annual_rx=annual_est,
            min_val=min_val, max_val=max_val,
            confidence="medium" if medical_facilities else "low",
            daily_rx=int(total_daily_rx),
            breakdown=breakdown,
            methodology=methodology,
            references=[
                {
                    "name": "åšç”ŸåŠ´åƒçœã€Œå—ç™‚è¡Œå‹•èª¿æŸ»ã€",
                    "desc": "è¨ºç™‚ç§‘åˆ¥å‡¦æ–¹ç®‹ç™ºè¡Œç‡ã®æ ¹æ‹ ãƒ‡ãƒ¼ã‚¿",
                    "url": "https://www.mhlw.go.jp/toukei/list/35-34.html",
                },
                {
                    "name": "åšç”ŸåŠ´åƒçœã€Œè–¬å±€ãƒ»è–¬å‰¤å¸«æ©Ÿèƒ½ã«é–¢ã™ã‚‹å®Ÿæ…‹èª¿æŸ»ã€",
                    "desc": f"é™¢å¤–å‡¦æ–¹ç‡ï¼ˆå…¨å›½å¹³å‡ {self.OUTPATIENT_RX_RATE:.1%}ï¼‰ã®æ ¹æ‹ ãƒ‡ãƒ¼ã‚¿",
                    "url": "https://www.mhlw.go.jp/stf/seisakunitsuite/bunya/kenkou_iryou/iyakuhin/yakkyoku_yakuzaisi/index.html",
                },
                {
                    "name": "OpenStreetMap (Overpass API)",
                    "desc": "è¿‘éš£åŒ»ç™‚æ–½è¨­ãƒ‡ãƒ¼ã‚¿ã®ã‚½ãƒ¼ã‚¹",
                    "url": "https://overpass-api.de/",
                },
            ],
        )

    def _calc_pharmacy_share(
        self,
        facility: NearbyFacility,
        pharmacy_lat: float,
        pharmacy_lon: float,
        competing_pharmacies: List[NearbyFacility],
    ) -> Tuple[float, str]:
        dist = OverpassSearcher._haversine(
            facility.lat, facility.lon, pharmacy_lat, pharmacy_lon
        )
        if dist <= 50:
            base_share, reason = 0.75, "50mä»¥å†…ï¼ˆå®Ÿè³ªé–€å‰ï¼‰"
        elif dist <= 150:
            base_share, reason = 0.50, "150mä»¥å†…ï¼ˆè¿‘æ¥ç«‹åœ°ï¼‰"
        elif dist <= 300:
            base_share, reason = 0.30, "300mä»¥å†…ï¼ˆå¾’æ­©åœï¼‰"
        else:
            base_share, reason = 0.15, "500mä»¥å†…ï¼ˆè‡ªè»¢è»Šåœï¼‰"

        competing_near = [
            p for p in competing_pharmacies
            if OverpassSearcher._haversine(facility.lat, facility.lon, p.lat, p.lon) < 300
        ]
        n_comp = len(competing_near)
        if n_comp > 0:
            target_w = 1.0 / max(dist, 10)
            comp_ws = [
                1.0 / max(OverpassSearcher._haversine(facility.lat, facility.lon, p.lat, p.lon), 10)
                for p in competing_near
            ]
            adjusted = base_share * (target_w / (target_w + sum(comp_ws)))
            reason += f"ï¼ˆç«¶åˆ{n_comp}ä»¶ã§æŒ‰åˆ†ï¼‰"
        else:
            adjusted = base_share
            reason += "ï¼ˆè¿‘éš£ã«ç«¶åˆãªã—ï¼‰"

        return min(adjusted, 0.90), reason


# ---------------------------------------------------------------------------
# 6. æ–¹æ³•â‘¡ å•†åœäººå£å‹•æ…‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ
# ---------------------------------------------------------------------------

class Method2Predictor:
    def predict(
        self,
        pharmacy_lat: float,
        pharmacy_lon: float,
        competing_pharmacies: List[NearbyFacility],
        area_density: int,
        radius_m: int,
        density_source: str = "",
        radius_reason: str = "",
    ) -> PredictionResult:
        area_km2 = math.pi * (radius_m / 1000) ** 2
        total_population = int(area_km2 * area_density)

        age_breakdown = []
        total_annual_rx = 0
        for age_grp, ratio in AGE_DISTRIBUTION.items():
            pop = int(total_population * ratio)
            visit_rate = VISIT_RATE_BY_AGE[age_grp]
            annual_visits = pop * visit_rate
            annual_rx = int(
                annual_visits
                * NATIONAL_STATS["prescription_per_visit"]
                * NATIONAL_STATS["outpatient_rx_rate"]
            )
            age_breakdown.append({
                "å¹´é½¢å±¤": age_grp,
                "æ¨è¨ˆäººå£": f"{pop:,}äºº",
                "å—è¨ºç‡": f"{visit_rate}å›/å¹´",
                "å¹´é–“å—è¨ºå›æ•°": f"{annual_visits:,.0f}å›",
                "å¹´é–“å‡¦æ–¹ç®‹æ•°": f"{annual_rx:,}æš",
            })
            total_annual_rx += annual_rx

        market_share, share_reason = self._calc_market_share(
            pharmacy_lat, pharmacy_lon, competing_pharmacies
        )

        annual_est = int(total_annual_rx * market_share)
        min_val = int(annual_est * 0.55)
        max_val = int(annual_est * 1.80)

        density_note = f"ï¼ˆ{density_source}ï¼‰" if density_source else ""
        radius_note = f"ï¼ˆ{radius_reason}ï¼‰" if radius_reason else ""

        methodology = [
            "### æ–¹æ³•â‘¡ ãƒ­ã‚¸ãƒƒã‚¯: å•†åœäººå£å‹•æ…‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ",
            "",
            "**ç®—å‡ºå¼**:",
            "ã€€å•†åœäººå£ Ã— å¹´é½¢å±¤åˆ¥å—è¨ºç‡ Ã— å‡¦æ–¹ç®‹ç™ºè¡Œç‡(65%)",
            "ã€€Ã— é™¢å¤–å‡¦æ–¹ç‡(74.5%) Ã— å½“è–¬å±€å¸‚å ´ã‚·ã‚§ã‚¢",
            "",
            f"**å•†åœè¨­å®š**: åŠå¾„{radius_m}m {radius_note}ï¼ˆé¢ç©: {area_km2:.2f}kmÂ²ï¼‰",
            f"**äººå£å¯†åº¦**: {area_density:,}äºº/kmÂ² {density_note}",
            f"**æ¨è¨ˆå•†åœäººå£**: {total_population:,}äºº",
            "",
            "**å¹´é½¢å±¤åˆ¥å¤–æ¥å—è¨ºç‡ã®æ ¹æ‹ **: åšç”ŸåŠ´åƒçœã€Œæ‚£è€…èª¿æŸ»ã€2020å¹´",
            f"ã€€0-14æ­³: {VISIT_RATE_BY_AGE['0-14æ­³']}å›/å¹´,  "
            f"15-44æ­³: {VISIT_RATE_BY_AGE['15-44æ­³']}å›/å¹´,  "
            f"45-64æ­³: {VISIT_RATE_BY_AGE['45-64æ­³']}å›/å¹´",
            f"ã€€65-74æ­³: {VISIT_RATE_BY_AGE['65-74æ­³']}å›/å¹´, "
            f"75æ­³ä»¥ä¸Š: {VISIT_RATE_BY_AGE['75æ­³ä»¥ä¸Š']}å›/å¹´",
            "",
            f"**å•†åœå†…å¹´é–“å‡¦æ–¹ç®‹ç·æ•°**: {total_annual_rx:,}æš",
            f"**å½“è–¬å±€æ¨è¨ˆå¸‚å ´ã‚·ã‚§ã‚¢**: {market_share:.1%}",
            f"  æ ¹æ‹ : {share_reason}",
            f"**æ¨è¨ˆå¹´é–“å‡¦æ–¹ç®‹æšæ•°**: **{annual_est:,}æš/å¹´**",
        ]

        return PredictionResult(
            method_name="æ–¹æ³•â‘¡: å•†åœäººå£å‹•æ…‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ",
            annual_rx=annual_est,
            min_val=min_val, max_val=max_val,
            confidence="low",
            daily_rx=int(annual_est / NATIONAL_STATS["working_days"]),
            breakdown=age_breakdown,
            methodology=methodology,
            references=[
                {
                    "name": "åšç”ŸåŠ´åƒçœã€Œæ‚£è€…èª¿æŸ»ã€2020å¹´",
                    "desc": "å¹´é½¢å±¤åˆ¥å¤–æ¥å—è¨ºç‡ã®æ ¹æ‹ ãƒ‡ãƒ¼ã‚¿",
                    "url": "https://www.mhlw.go.jp/toukei/saikin/hw/kanja/20/index.html",
                },
                {
                    "name": "ç·å‹™çœã€Œå›½å‹¢èª¿æŸ»ã€2020å¹´",
                    "desc": "æ—¥æœ¬ã®å¹´é½¢åˆ¥äººå£åˆ†å¸ƒãƒ»åœ°åŒºåˆ¥äººå£å¯†åº¦",
                    "url": "https://www.stat.go.jp/data/kokusei/2020/",
                },
            ],
        )

    def _calc_market_share(
        self,
        pharmacy_lat: float,
        pharmacy_lon: float,
        competing_pharmacies: List[NearbyFacility],
    ) -> Tuple[float, str]:
        n = len(competing_pharmacies)
        if n == 0:
            return 0.65, "å•†åœå†…ã«ç«¶åˆè–¬å±€ãªã—ï¼ˆç‹¬å è£œæ­£0.65ï¼‰"
        target_w = 1.0
        comp_ws = [1.0 / max(p.distance_m, 20) ** 2 for p in competing_pharmacies]
        raw_share = target_w / (target_w + sum(comp_ws))
        share = min(raw_share, 0.80)
        return share, f"è·é›¢é‡ã¿ä»˜ãã‚·ã‚§ã‚¢ï¼ˆç«¶åˆ{n}ä»¶ï¼‰: {share:.1%}"


# ---------------------------------------------------------------------------
# 7. ç«¶åˆãƒãƒƒãƒ—ï¼ˆFoliumï¼‰
# ---------------------------------------------------------------------------

def build_competitor_map(
    pharmacy_name: str,
    pharmacy_lat: float,
    pharmacy_lon: float,
    medical_facilities: List[NearbyFacility],
    competing_pharmacies: List[NearbyFacility],
    radius_m: int = 500,
) -> folium.Map:
    m = folium.Map(location=[pharmacy_lat, pharmacy_lon], zoom_start=16)

    folium.Circle(
        location=[pharmacy_lat, pharmacy_lon],
        radius=radius_m,
        color="#FF4444", fill=True, fill_opacity=0.05, weight=2,
        popup=f"å•†åœåŠå¾„ {radius_m}m",
    ).add_to(m)

    folium.Marker(
        location=[pharmacy_lat, pharmacy_lon],
        popup=folium.Popup(f"<b>ğŸ’Š {pharmacy_name}</b><br>ã€åˆ†æå¯¾è±¡è–¬å±€ã€‘", max_width=200),
        tooltip=f"ğŸ’Š {pharmacy_name}ï¼ˆåˆ†æå¯¾è±¡ï¼‰",
        icon=folium.Icon(color="red", icon="plus-sign", prefix="glyphicon"),
    ).add_to(m)

    for fac in medical_facilities:
        color = "blue" if fac.facility_type == "hospital" else "cadetblue"
        icon_name = "h-sign" if fac.facility_type == "hospital" else "user-md"
        ftype_label = "ğŸ¥ ç—…é™¢" if fac.facility_type == "hospital" else "ğŸ¨ ã‚¯ãƒªãƒ‹ãƒƒã‚¯"
        inhouse_note = "ï¼ˆé™¢å†…è–¬å±€ã‚ã‚Šï¼‰" if fac.has_inhouse_pharmacy else ""
        popup_html = (
            f"<b>{ftype_label} {fac.name}</b>{inhouse_note}<br>"
            f"è¨ºç™‚ç§‘: {fac.specialty}<br>"
            f"è·é›¢: {fac.distance_m:.0f}m<br>"
            f"æ¨è¨ˆå¤–æ¥: {fac.daily_outpatients}äºº/æ—¥"
        )
        if fac.mhlw_annual_outpatients:
            popup_html += f"<br>MHLWå¹´é–“å¤–æ¥: {fac.mhlw_annual_outpatients:,}äºº"
        folium.Marker(
            location=[fac.lat, fac.lon],
            popup=folium.Popup(popup_html, max_width=250),
            tooltip=f"{ftype_label} {fac.name} ({fac.distance_m:.0f}m)",
            icon=folium.Icon(color=color, icon=icon_name, prefix="glyphicon"),
        ).add_to(m)
        folium.PolyLine(
            [[fac.lat, fac.lon], [pharmacy_lat, pharmacy_lon]],
            color=color, weight=1.5, opacity=0.5,
        ).add_to(m)

    for ph in competing_pharmacies:
        is_chain = any(c in ph.name for c in MAJOR_CHAINS)
        chain_note = "ï¼ˆå¤§æ‰‹ãƒã‚§ãƒ¼ãƒ³ï¼‰" if is_chain else ""
        popup_html = f"<b>ğŸ’Š {ph.name}</b>{chain_note}<br>è·é›¢: {ph.distance_m:.0f}m"
        folium.Marker(
            location=[ph.lat, ph.lon],
            popup=folium.Popup(popup_html, max_width=200),
            tooltip=f"ğŸ’Š ç«¶åˆ: {ph.name} ({ph.distance_m:.0f}m)",
            icon=folium.Icon(color="green", icon="shopping-cart", prefix="glyphicon"),
        ).add_to(m)

    return m


# ---------------------------------------------------------------------------
# 8. ä¹–é›¢è©•ä¾¡
# ---------------------------------------------------------------------------

def calc_deviation(actual: int, predicted: int) -> Tuple[float, str, str]:
    if actual <= 0:
        return 0.0, "N/A", "neutral"
    pct = (predicted - actual) / actual * 100
    label = f"+{pct:.1f}%" if pct >= 0 else f"{pct:.1f}%"
    color = "normal" if abs(pct) < 20 else ("inverse" if abs(pct) < 50 else "off")
    return pct, label, color


# ---------------------------------------------------------------------------
# 9. UI ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°é–¢æ•°
# ---------------------------------------------------------------------------

def render_auto_params_panel(analysis: FullAnalysis) -> None:
    """è‡ªå‹•è¨ˆç®—ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ‘ãƒãƒ«ï¼ˆåº§æ¨™ãƒ»å¯†åº¦ãƒ»å•†åœåŠå¾„ï¼‰ã‚’è¡¨ç¤º"""
    st.markdown("### ğŸ“ è‡ªå‹•è¨ˆç®—ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿")

    if analysis.pharmacy_lat and analysis.pharmacy_lon:
        col_coord, col_dens, col_rad, col_pop = st.columns(4)
        with col_coord:
            st.metric(
                "ğŸŒ å–å¾—åº§æ¨™",
                f"{analysis.pharmacy_lat:.5f}",
                delta=f"çµŒåº¦: {analysis.pharmacy_lon:.5f}",
                delta_color="off",
            )
            if analysis.geocode_display:
                st.caption(f"ğŸ“ {analysis.geocode_display[:60]}")
        with col_dens:
            st.metric(
                "ğŸ˜ äººå£å¯†åº¦",
                f"{analysis.area_density:,}äºº/kmÂ²",
                help=analysis.area_density_source,
            )
            st.caption(f"ğŸ“‹ {analysis.area_density_source[:40]}")
        with col_rad:
            gate_icon = "ğŸšª" if analysis.is_gate_pharmacy else "ğŸ“"
            st.metric(
                f"{gate_icon} å•†åœåŠå¾„",
                f"{analysis.commercial_radius}m",
            )
            st.caption(f"ğŸ“ {analysis.commercial_radius_reason[:45]}")
        with col_pop:
            area_km2 = math.pi * (analysis.commercial_radius / 1000) ** 2
            catchment_pop = int(area_km2 * analysis.area_density)
            st.metric(
                "ğŸ‘¥ æ¨è¨ˆå•†åœäººå£",
                f"{catchment_pop:,}äºº",
                help=f"Ï€Ã—{analysis.commercial_radius}mÂ² Ã— {analysis.area_density:,}äºº/kmÂ²",
            )
            if analysis.is_gate_pharmacy:
                st.caption(f"ğŸšª é–€å‰è–¬å±€: {analysis.gate_pharmacy_reason[:30]}")
    else:
        st.warning("âš  åº§æ¨™å–å¾—ã«å¤±æ•—ã—ãŸãŸã‚ã€ç©ºé–“åˆ†æã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸã€‚ä½æ‰€ã®æ›¸å¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        st.info(
            "ğŸ’¡ **ãƒ’ãƒ³ãƒˆ**: ä½æ‰€ãŒã€Œãƒ“ãƒ«åã€‡ã€‡å·å®¤ã€ãªã©ã§çµ‚ã‚ã‚‹å ´åˆã€"
            "éƒ½é“åºœçœŒ+å¸‚åŒºç”ºæ‘+ä¸ç›®ç•ªåœ° ã¾ã§ã®ä½æ‰€ã§å†æ¤œç´¢ã™ã‚‹ã¨ã‚¸ã‚ªã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãŒæ”¹å–„ã™ã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚"
        )
        st.metric("ğŸ˜ æ¨è¨ˆäººå£å¯†åº¦ï¼ˆä½æ‰€ã‹ã‚‰ï¼‰", f"{analysis.area_density:,}äºº/kmÂ²")
        st.caption(f"ğŸ“‹ {analysis.area_density_source}")


def render_comparison_banner(analysis: FullAnalysis) -> None:
    st.markdown("## ğŸ“Š äºˆæ¸¬å€¤ vs åšåŠ´çœå®Ÿç¸¾å€¤ æ¯”è¼ƒ")

    actual = analysis.mhlw_annual_rx
    m1 = analysis.method1
    m2 = analysis.method2

    cols = st.columns(4)
    with cols[0]:
        if actual:
            st.metric("ğŸ¥ MHLWå®Ÿç¸¾å€¤", f"{actual:,} æš/å¹´")
            st.caption("ğŸŸ¢ ä¿¡é ¼åº¦: é«˜ï¼ˆå®Ÿç¸¾å€¤ï¼‰")
        else:
            st.metric("ğŸ¥ MHLWå®Ÿç¸¾å€¤", "è¨˜è¼‰ãªã—")
            st.caption("âš  å½“è©²è–¬å±€ã¯æœªå ±å‘Š")

    with cols[1]:
        if m1:
            st.metric(
                "â‘  åŒ»ç™‚æ©Ÿé–¢ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ",
                f"{m1.annual_rx:,} æš/å¹´",
                delta=calc_deviation(actual, m1.annual_rx)[1] if actual else None,
            )
            st.caption(f"ãƒ¬ãƒ³ã‚¸: {m1.min_val:,}ã€œ{m1.max_val:,}")

    with cols[2]:
        if m2:
            st.metric(
                "â‘¡ äººå£å‹•æ…‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ",
                f"{m2.annual_rx:,} æš/å¹´",
                delta=calc_deviation(actual, m2.annual_rx)[1] if actual else None,
            )
            st.caption(f"ãƒ¬ãƒ³ã‚¸: {m2.min_val:,}ã€œ{m2.max_val:,}")

    with cols[3]:
        if actual and m1 and m2:
            avg_pred = (m1.annual_rx + m2.annual_rx) // 2
            pct, label, _ = calc_deviation(actual, avg_pred)
            st.metric(
                "äºˆæ¸¬å¹³å‡ vs å®Ÿç¸¾",
                f"{avg_pred:,} æš/å¹´",
                delta=label,
                delta_color="normal" if abs(pct) < 30 else "inverse",
            )
            st.caption("ï¼ˆâ‘ ã¨â‘¡ã®å˜ç´”å¹³å‡ï¼‰")


def render_competitor_table(
    medical_facilities: List[NearbyFacility],
    competing_pharmacies: List[NearbyFacility],
) -> None:
    st.markdown("### ğŸ—º è¿‘éš£ã®åŒ»ç™‚æ–½è¨­ãƒ»ç«¶åˆè–¬å±€")

    col_med, col_ph = st.columns(2)
    with col_med:
        st.markdown(f"**åŒ»ç™‚æ–½è¨­ï¼ˆ{len(medical_facilities)}ä»¶ï¼‰**")
        if medical_facilities:
            import pandas as pd
            rows = [{
                "æ–½è¨­å": f.name,
                "ç¨®åˆ¥": "ç—…é™¢" if f.facility_type == "hospital" else "ã‚¯ãƒªãƒ‹ãƒƒã‚¯",
                "è·é›¢": f"{f.distance_m:.0f}m",
                "è¨ºç™‚ç§‘": f.specialty,
                "å¤–æ¥/æ—¥(æ¨è¨ˆ)": f"{f.daily_outpatients}äºº",
                "é™¢å†…è–¬å±€": "ã‚ã‚Š" if f.has_inhouse_pharmacy else "ãªã—",
            } for f in medical_facilities]
            st.dataframe(pd.DataFrame(rows), use_container_width=True, hide_index=True)
        else:
            st.info("æ¤œç´¢ç¯„å›²å†…ã«åŒ»ç™‚æ–½è¨­ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")

    with col_ph:
        st.markdown(f"**ç«¶åˆè–¬å±€ï¼ˆ{len(competing_pharmacies)}ä»¶ï¼‰**")
        if competing_pharmacies:
            import pandas as pd
            rows = [{
                "è–¬å±€å": p.name,
                "è·é›¢": f"{p.distance_m:.0f}m",
                "ãƒã‚§ãƒ¼ãƒ³": "ã¯ã„" if any(c in p.name for c in MAJOR_CHAINS) else "ç‹¬ç«‹",
            } for p in competing_pharmacies]
            st.dataframe(pd.DataFrame(rows), use_container_width=True, hide_index=True)
        else:
            st.info("æ¤œç´¢ç¯„å›²å†…ã«ç«¶åˆè–¬å±€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")


# ---------------------------------------------------------------------------
# 10. ãƒ¡ã‚¤ãƒ³ UI
# ---------------------------------------------------------------------------

def main() -> None:
    st.set_page_config(
        page_title="è–¬å±€ å‡¦æ–¹ç®‹æšæ•° å¤šé¢çš„äºˆæ¸¬ v2.1",
        page_icon="ğŸ”¬",
        layout="wide",
        initial_sidebar_state="collapsed",
    )

    st.title("ğŸ”¬ è–¬å±€ å¹´é–“å‡¦æ–¹ç®‹æšæ•° å¤šé¢çš„äºˆæ¸¬ãƒ„ãƒ¼ãƒ« v2.1")
    st.markdown(
        "åšç”ŸåŠ´åƒçœã®å®Ÿç¸¾ãƒ‡ãƒ¼ã‚¿ã¨ã€**è¿‘éš£åŒ»ç™‚æ©Ÿé–¢ã‚¢ãƒ—ãƒ­ãƒ¼ãƒï¼ˆæ–¹æ³•â‘ ï¼‰**ãƒ»"
        "**å•†åœäººå£å‹•æ…‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒï¼ˆæ–¹æ³•â‘¡ï¼‰** ã®2ç¨®é¡ã®äºˆæ¸¬ã‚’ä¸¦åˆ—è¡¨ç¤ºã—ã¾ã™ã€‚\n\n"
        "ğŸ†• **v2.1ã®æ”¹å–„ç‚¹**: ã‚¸ã‚ªã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ä¿®æ­£ / äººå£å¯†åº¦ãƒ»å•†åœåŠå¾„ã‚’ä½æ‰€ã‹ã‚‰è‡ªå‹•è¨ˆç®—"
    )

    for k, v in [
        ("candidates", []),
        ("selected_idx", 0),
        ("analysis", None),
        ("search_done", False),
    ]:
        if k not in st.session_state:
            st.session_state[k] = v

    # ================================================================
    # STEP 1: è–¬å±€æ¤œç´¢
    # ================================================================
    st.markdown("### STEP 1 â€” è–¬å±€åã§æ¤œç´¢ï¼ˆåšç”ŸåŠ´åƒçœãƒãƒ¼ã‚¿ãƒ«ï¼‰")

    col_kw, col_pref = st.columns([3, 1])
    with col_kw:
        keyword = st.text_input(
            "è–¬å±€åï¼ˆä¸€éƒ¨ã§ã‚‚å¯ï¼‰",
            placeholder="ä¾‹: ã‚¢ã‚¤ã‚»ã‚¤è–¬å±€ æ­¦è”µå°æ‰ / æ—¥æœ¬èª¿å‰¤ æ–°å®¿",
            key="v21_keyword",
        )
    with col_pref:
        prefecture = st.selectbox("éƒ½é“åºœçœŒï¼ˆä»»æ„ï¼‰", ["ï¼ˆæŒ‡å®šãªã—ï¼‰"] + PREFECTURES, key="v21_pref")

    if st.button("ğŸ” å€™è£œã‚’æ¤œç´¢", type="primary"):
        st.session_state["analysis"] = None
        st.session_state["search_done"] = False
        pref_code = PREFECTURE_CODES.get(prefecture, "")
        with st.spinner("MHLWãƒãƒ¼ã‚¿ãƒ«ã‚’æ¤œç´¢ä¸­â€¦"):
            scraper = MHLWScraper()
            candidates, total, status = scraper.search_pharmacy_candidates(keyword.strip(), pref_code)
        st.session_state["candidates"] = candidates
        if candidates:
            st.success(f"âœ… {status}ï¼ˆå…¨{total}ä»¶ï¼‰")
        else:
            st.warning("å€™è£œãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")

    # ================================================================
    # STEP 2: å€™è£œé¸æŠ + è‡ªå‹•è¨ˆç®—ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
    # ================================================================
    candidates: List[PharmacyCandidate] = st.session_state.get("candidates", [])
    analysis: Optional[FullAnalysis] = st.session_state.get("analysis")

    if candidates and analysis is None:
        st.markdown("---")
        st.markdown("### STEP 2 â€” è–¬å±€é¸æŠ")

        options = [
            f"{c.name}ã€€{'ï¼ˆ' + c.address[:35] + 'ï¼‰' if c.address else ''}"
            for c in candidates
        ]
        sel_label = st.selectbox("å€™è£œä¸€è¦§", options, key="v21_candidate_select")
        sel_idx = options.index(sel_label)
        sel_candidate = candidates[sel_idx]
        st.caption(f"ğŸ“ ä½æ‰€: {sel_candidate.address or 'ä¸æ˜'}")

        # â”€â”€ è‡ªå‹•è¨ˆç®—ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆä½æ‰€ã‹ã‚‰å³æ™‚è¨ˆç®—ï¼‰
        if sel_candidate.address:
            preview_density, preview_density_src = get_population_density(sel_candidate.address)
            preview_r, preview_r_reason = calc_commercial_radius(preview_density, False, "")
            est_pop = int(math.pi * (preview_r / 1000) ** 2 * preview_density)

            with st.expander("ğŸ“ è‡ªå‹•è¨ˆç®—ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆä½æ‰€ã‹ã‚‰æ¨å®šï¼‰", expanded=True):
                st.info(
                    "ä»¥ä¸‹ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯ä½æ‰€ã‹ã‚‰è‡ªå‹•è¨ˆç®—ã•ã‚Œã¾ã™ã€‚"
                    "åˆ†æå®Ÿè¡Œå¾Œã«è¿‘éš£æ–½è¨­ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ãé–€å‰è–¬å±€åˆ¤å®šãŒè¡Œã‚ã‚Œã€"
                    "å•†åœåŠå¾„ãŒæ›´æ–°ã•ã‚Œã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚"
                )
                p1, p2, p3 = st.columns(3)
                p1.metric(
                    "ğŸ˜ æ¨è¨ˆäººå£å¯†åº¦",
                    f"{preview_density:,}äºº/kmÂ²",
                    help=preview_density_src,
                )
                p2.metric(
                    "ğŸ“ åˆæœŸå•†åœåŠå¾„",
                    f"{preview_r}m",
                    help=preview_r_reason,
                )
                p3.metric("ğŸ‘¥ æ¨è¨ˆå•†åœäººå£", f"{est_pop:,}äºº")
                st.caption(f"ğŸ—‚ äººå£å¯†åº¦å‡ºå…¸: {preview_density_src}")
                st.caption(f"ğŸ“ å•†åœåŠå¾„ã®æ ¹æ‹ : {preview_r_reason}")

        # â”€â”€ ã‚ªãƒ—ã‚·ãƒ§ãƒ³
        try_mhlw_medical = st.checkbox(
            "è¿‘éš£åŒ»ç™‚æ–½è¨­ã®MHLWãƒ‡ãƒ¼ã‚¿ç…§ä¼šï¼ˆæ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™ï¼‰", value=False,
            help="ONã«ã™ã‚‹ã¨å¤–æ¥æ‚£è€…æ•°ã®ç²¾åº¦ãŒä¸ŠãŒã‚Šã¾ã™ãŒã€å„æ–½è¨­ã”ã¨ã«MHLWã¸å•ã„åˆã‚ã›ã‚‹ãŸã‚æ•°åˆ†ã‹ã‹ã‚Šã¾ã™",
        )

        if st.button("ğŸš€ å¤šé¢çš„åˆ†æã‚’å®Ÿè¡Œ", type="primary", use_container_width=True):
            run_analysis(sel_candidate, try_mhlw_medical)

    # ================================================================
    # STEP 3: çµæœè¡¨ç¤º
    # ================================================================
    if analysis:
        st.markdown("---")
        st.markdown(f"## çµæœ: `{analysis.pharmacy_name}`")
        st.caption(f"ä½æ‰€: {analysis.pharmacy_address}")

        # è‡ªå‹•è¨ˆç®—ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ‘ãƒãƒ«
        render_auto_params_panel(analysis)
        st.markdown("---")

        # æ¯”è¼ƒãƒãƒŠãƒ¼
        render_comparison_banner(analysis)
        st.markdown("---")

        tab_map, tab_m1, tab_m2, tab_mhlw, tab_log = st.tabs([
            "ğŸ—º ç«¶åˆãƒãƒƒãƒ—",
            "â‘  åŒ»ç™‚æ©Ÿé–¢ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ",
            "â‘¡ äººå£å‹•æ…‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ",
            "ğŸ¥ åšåŠ´çœãƒ‡ãƒ¼ã‚¿",
            "ğŸ” æ¤œç´¢ãƒ­ã‚°",
        ])

        with tab_map:
            if analysis.pharmacy_lat and analysis.pharmacy_lon:
                st.markdown("**å‡¡ä¾‹**: ğŸ”´ åˆ†æå¯¾è±¡è–¬å±€ã€€ğŸ”µ ç—…é™¢ã€€ğŸ”· ã‚¯ãƒªãƒ‹ãƒƒã‚¯ã€€ğŸŸ¢ ç«¶åˆè–¬å±€")
                st.caption(f"å•†åœå††ï¼ˆèµ¤ç‚¹ç·šï¼‰: åŠå¾„ {analysis.commercial_radius}m")
                folium_map = build_competitor_map(
                    analysis.pharmacy_name,
                    analysis.pharmacy_lat,
                    analysis.pharmacy_lon,
                    analysis.nearby_medical,
                    analysis.nearby_pharmacies,
                    analysis.commercial_radius,
                )
                st_folium(folium_map, width=None, height=500, use_container_width=True)
            else:
                st.warning("ä½æ‰€ã‹ã‚‰åº§æ¨™ã‚’å–å¾—ã§ããªã‹ã£ãŸãŸã‚ã€ãƒãƒƒãƒ—ã‚’è¡¨ç¤ºã§ãã¾ã›ã‚“")
            render_competitor_table(analysis.nearby_medical, analysis.nearby_pharmacies)

        with tab_m1:
            if analysis.method1:
                m1 = analysis.method1
                st.metric("å¹´é–“æ¨è¨ˆå‡¦æ–¹ç®‹æšæ•°ï¼ˆæ–¹æ³•â‘ ï¼‰", f"{m1.annual_rx:,} æš/å¹´")
                st.caption(f"ãƒ¬ãƒ³ã‚¸: {m1.min_val:,}ã€œ{m1.max_val:,}æš/å¹´ | 1æ—¥æ›ç®—: {m1.daily_rx}æš/æ—¥")
                if m1.breakdown:
                    st.markdown("#### æ–½è¨­åˆ¥ å‡¦æ–¹ç®‹æµå…¥å†…è¨³")
                    import pandas as pd
                    st.dataframe(pd.DataFrame(m1.breakdown), use_container_width=True, hide_index=True)
                st.markdown("#### æ¨è¨ˆãƒ­ã‚¸ãƒƒã‚¯")
                for line in m1.methodology:
                    st.markdown(line)
                st.markdown("#### å‚ç…§ã‚½ãƒ¼ã‚¹")
                for ref in m1.references:
                    with st.expander(ref["name"]):
                        st.write(ref.get("desc", ""))
                        if ref.get("url"):
                            st.markdown(f"ğŸ”— [{ref['url']}]({ref['url']})")
            else:
                st.info("æ–¹æ³•â‘ ã®åˆ†æãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ï¼ˆåº§æ¨™å–å¾—å¤±æ•—ã®å¯èƒ½æ€§ï¼‰")

        with tab_m2:
            if analysis.method2:
                m2 = analysis.method2
                st.metric("å¹´é–“æ¨è¨ˆå‡¦æ–¹ç®‹æšæ•°ï¼ˆæ–¹æ³•â‘¡ï¼‰", f"{m2.annual_rx:,} æš/å¹´")
                st.caption(f"ãƒ¬ãƒ³ã‚¸: {m2.min_val:,}ã€œ{m2.max_val:,}æš/å¹´ | 1æ—¥æ›ç®—: {m2.daily_rx}æš/æ—¥")
                if m2.breakdown:
                    st.markdown("#### å¹´é½¢å±¤åˆ¥ å‡¦æ–¹ç®‹æ•°å†…è¨³")
                    import pandas as pd
                    st.dataframe(pd.DataFrame(m2.breakdown), use_container_width=True, hide_index=True)
                st.markdown("#### æ¨è¨ˆãƒ­ã‚¸ãƒƒã‚¯")
                for line in m2.methodology:
                    st.markdown(line)
                st.markdown("#### å‚ç…§ã‚½ãƒ¼ã‚¹")
                for ref in m2.references:
                    with st.expander(ref["name"]):
                        st.write(ref.get("desc", ""))
                        if ref.get("url"):
                            st.markdown(f"ğŸ”— [{ref['url']}]({ref['url']})")
            else:
                st.info("æ–¹æ³•â‘¡ã®åˆ†æãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")

        with tab_mhlw:
            if analysis.mhlw_annual_rx:
                st.success(f"âœ… åšåŠ´çœå®Ÿç¸¾å€¤: **{analysis.mhlw_annual_rx:,}æš/å¹´**")
                st.markdown(f"ğŸ”— [MHLWãƒãƒ¼ã‚¿ãƒ«ã§ç¢ºèª]({analysis.mhlw_source_url})")
            else:
                st.warning("åšåŠ´çœãƒãƒ¼ã‚¿ãƒ«ã«å‡¦æ–¹ç®‹æšæ•°ã®è¨˜è¼‰ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸï¼ˆæœªå ±å‘Šï¼‰")
                if analysis.mhlw_source_url:
                    st.markdown(f"ğŸ”— [MHLWãƒãƒ¼ã‚¿ãƒ«ã§ç¢ºèª]({analysis.mhlw_source_url})")

        with tab_log:
            st.code("\n".join(analysis.search_log))

    # åˆæœŸç”»é¢
    if not candidates and analysis is None:
        st.markdown("---")
        col1, col2, col3 = st.columns(3)
        col1.markdown(
            "**â‘  åšåŠ´çœå®Ÿãƒ‡ãƒ¼ã‚¿å–å¾—**\n\n"
            "è–¬å±€æ©Ÿèƒ½æƒ…å ±æä¾›åˆ¶åº¦ã‹ã‚‰\nã€Œç·å–æ‰±å‡¦æ–¹ç®‹æ•°ã€ã‚’ç›´æ¥å–å¾—"
        )
        col2.markdown(
            "**â‘¡ è¿‘éš£åŒ»ç™‚æ©Ÿé–¢ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ**\n\n"
            "OSMã§è¿‘éš£ã‚¯ãƒªãƒ‹ãƒƒã‚¯ãƒ»ç—…é™¢ã‚’æ¤œç´¢ã—\nè¨ºç™‚ç§‘åˆ¥å‡¦æ–¹ç®‹ç™ºè¡Œç‡ã‹ã‚‰äºˆæ¸¬"
        )
        col3.markdown(
            "**â‘¢ å•†åœäººå£å‹•æ…‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ**\n\n"
            "ä½æ‰€ã‹ã‚‰äººå£å¯†åº¦ãƒ»å•†åœåŠå¾„ã‚’è‡ªå‹•è¨ˆç®—\nå¹´é½¢åˆ¥å—è¨ºç‡ Ã— å¸‚å ´ã‚·ã‚§ã‚¢ã§äºˆæ¸¬"
        )


# ---------------------------------------------------------------------------
# 11. åˆ†æå®Ÿè¡Œ
# ---------------------------------------------------------------------------

def run_analysis(
    candidate: PharmacyCandidate,
    try_mhlw_medical: bool,
) -> None:
    """ãƒ•ãƒ«åˆ†æã‚’å®Ÿè¡Œã—ã¦ session_state ã«ä¿å­˜"""
    log: List[str] = []
    progress = st.progress(0, text="åˆ†æé–‹å§‹â€¦")

    # â”€â”€ STEP A: MHLW ã‹ã‚‰è–¬å±€è©³ç´°ã‚’å–å¾—
    progress.progress(10, text="[1/6] MHLW: è–¬å±€è©³ç´°ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­â€¦")
    scraper = MHLWScraper()
    scraper.initialize_session()
    detail, detail_msg = scraper.get_pharmacy_detail(candidate)
    log.append(f"[MHLW è–¬å±€è©³ç´°] {detail_msg}")

    mhlw_annual_rx = None
    pharmacy_address = candidate.address
    mhlw_source_url = candidate.href

    if detail:
        mhlw_annual_rx = detail.get("prescriptions_annual")
        if detail.get("address"):
            pharmacy_address = detail["address"]
        mhlw_source_url = detail.get("source_url", candidate.href)
        log.append(
            f"  å‡¦æ–¹ç®‹æ•°: {mhlw_annual_rx:,}æš/å¹´" if mhlw_annual_rx
            else "  å‡¦æ–¹ç®‹æ•°: è¨˜è¼‰ãªã—"
        )
        log.append(f"  ä½æ‰€: {pharmacy_address}")

    # â”€â”€ STEP B: äººå£å¯†åº¦ã‚’ä½æ‰€ã‹ã‚‰è‡ªå‹•è¨ˆç®—
    progress.progress(20, text="[2/6] ä½æ‰€ã‹ã‚‰äººå£å¯†åº¦ã‚’è‡ªå‹•è¨ˆç®—ä¸­â€¦")
    area_density, density_source = get_population_density(pharmacy_address)
    log.append(f"[äººå£å¯†åº¦] {area_density:,}äºº/kmÂ²ï¼ˆ{density_source}ï¼‰")

    # åˆæœŸå•†åœåŠå¾„ï¼ˆé–€å‰ãƒã‚§ãƒƒã‚¯å‰ï¼‰
    initial_radius, _ = calc_commercial_radius(area_density, False, "")
    # Overpass æ¤œç´¢ç¯„å›²ã¯åˆæœŸåŠå¾„ Ã— 1.5ï¼ˆé–€å‰ãƒã‚§ãƒƒã‚¯ã®ãŸã‚ä½™è£•ã‚’æŒãŸã›ã‚‹ï¼‰
    search_radius = max(int(initial_radius * 1.5), 600)

    # â”€â”€ STEP C: ã‚¸ã‚ªã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ï¼ˆä¿®æ­£æ¸ˆã¿GeocoderServiceï¼‰
    progress.progress(30, text="[3/6] ä½æ‰€ã‚’åº§æ¨™ã«å¤‰æ›ä¸­ï¼ˆNominatimï¼‰â€¦")
    geocoder = GeocoderService()
    lat, lon, geo_msg = geocoder.geocode(pharmacy_address)
    log.append(f"[Geocoding] {geo_msg}")

    geocode_display = ""
    if lat and lon:
        geocode_display = geo_msg
        log.append(f"  âœ… åº§æ¨™å–å¾—æˆåŠŸ: lat={lat:.5f}, lon={lon:.5f}")
    else:
        log.append("  âš  åº§æ¨™å–å¾—å¤±æ•— â†’ ç©ºé–“åˆ†æã‚’ã‚¹ã‚­ãƒƒãƒ—")

    # â”€â”€ STEP D: è¿‘éš£æ–½è¨­æ¤œç´¢ï¼ˆOSMï¼‰
    nearby_medical: List[NearbyFacility] = []
    nearby_pharmacies: List[NearbyFacility] = []

    if lat and lon:
        progress.progress(45, text=f"[4/6] è¿‘éš£æ–½è¨­ã‚’OSMã‹ã‚‰æ¤œç´¢ä¸­ï¼ˆåŠå¾„{search_radius}mï¼‰â€¦")
        time.sleep(1.1)  # Nominatim åˆ©ç”¨è¦ç´„æº–æ‹ 
        overpass = OverpassSearcher()
        nearby_medical, nearby_pharmacies, osm_msg = overpass.search_nearby(lat, lon, search_radius)
        log.append(f"[OSM Overpass] æ¤œç´¢åŠå¾„{search_radius}m â†’ {osm_msg}")

        # MHLWã§å„åŒ»ç™‚æ–½è¨­ã®å¤–æ¥æ‚£è€…æ•°ã‚’å–å¾—ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        if try_mhlw_medical and nearby_medical:
            progress.progress(55, text="[4.5/6] è¿‘éš£åŒ»ç™‚æ–½è¨­ã®MHLWãƒ‡ãƒ¼ã‚¿ã‚’ç…§ä¼šä¸­â€¦")
            for fac in nearby_medical[:5]:
                annual_op = scraper.get_medical_outpatient_data(fac.name)
                if annual_op:
                    fac.mhlw_annual_outpatients = annual_op
                    fac.daily_outpatients = annual_op // NATIONAL_STATS["working_days"]
                    log.append(f"  [MHLWåŒ»ç™‚æ©Ÿé–¢] {fac.name}: å¹´é–“å¤–æ¥{annual_op:,}äºº")
                time.sleep(0.5)

    # â”€â”€ STEP E: é–€å‰è–¬å±€åˆ¤å®š + å•†åœåŠå¾„ã®ç¢ºå®š
    progress.progress(65, text="[5/6] é–€å‰è–¬å±€åˆ¤å®šãƒ»å•†åœåŠå¾„ã‚’ç¢ºå®šä¸­â€¦")
    is_gate, gate_reason = detect_gate_pharmacy(candidate.name, nearby_medical)
    commercial_radius, radius_reason = calc_commercial_radius(area_density, is_gate, gate_reason)

    log.append(f"[é–€å‰åˆ¤å®š] is_gate={is_gate}  ç†ç”±: {gate_reason}")
    log.append(f"[å•†åœåŠå¾„] {commercial_radius}mï¼ˆ{radius_reason}ï¼‰")

    # â”€â”€ STEP F1: æ–¹æ³•â‘ äºˆæ¸¬
    progress.progress(75, text="[6/6] æ–¹æ³•â‘ : è¿‘éš£åŒ»ç™‚æ©Ÿé–¢ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§äºˆæ¸¬ä¸­â€¦")
    m1_predictor = Method1Predictor()
    method1 = m1_predictor.predict(
        lat or 0.0, lon or 0.0, nearby_medical, nearby_pharmacies
    ) if lat else None
    log.append(
        f"[æ–¹æ³•â‘ ] æ¨è¨ˆ: {method1.annual_rx:,}æš/å¹´" if method1
        else "[æ–¹æ³•â‘ ] ã‚¹ã‚­ãƒƒãƒ—ï¼ˆåº§æ¨™ãªã—ï¼‰"
    )

    # â”€â”€ STEP F2: æ–¹æ³•â‘¡äºˆæ¸¬
    progress.progress(88, text="[6/6] æ–¹æ³•â‘¡: å•†åœäººå£å‹•æ…‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§äºˆæ¸¬ä¸­â€¦")
    m2_predictor = Method2Predictor()
    method2 = m2_predictor.predict(
        lat or 0.0, lon or 0.0,
        nearby_pharmacies,
        area_density,
        commercial_radius,
        density_source=density_source,
        radius_reason=radius_reason,
    )
    log.append(f"[æ–¹æ³•â‘¡] æ¨è¨ˆ: {method2.annual_rx:,}æš/å¹´")

    progress.progress(100, text="å®Œäº†ï¼")
    progress.empty()

    st.session_state["analysis"] = FullAnalysis(
        pharmacy_name=candidate.name,
        pharmacy_address=pharmacy_address,
        pharmacy_lat=lat or 0.0,
        pharmacy_lon=lon or 0.0,
        geocode_display=geocode_display,
        mhlw_annual_rx=mhlw_annual_rx,
        mhlw_source_url=mhlw_source_url,
        method1=method1,
        method2=method2,
        nearby_medical=nearby_medical,
        nearby_pharmacies=nearby_pharmacies,
        area_density=area_density,
        area_density_source=density_source,
        commercial_radius=commercial_radius,
        commercial_radius_reason=radius_reason,
        is_gate_pharmacy=is_gate,
        gate_pharmacy_reason=gate_reason,
        search_log=log,
    )
    st.session_state["search_done"] = True
    st.rerun()


if __name__ == "__main__":
    main()
