"""
è–¬å±€ å¹´é–“å‡¦æ–¹ç®‹æšæ•° å¤šé¢çš„äºˆæ¸¬ãƒ„ãƒ¼ãƒ« v2.0
==========================================
v1ã®åšç”ŸåŠ´åƒçœå®Ÿãƒ‡ãƒ¼ã‚¿å–å¾—ã«åŠ ãˆã€2ç¨®é¡ã®ç‹¬ç«‹ã—ãŸäºˆæ¸¬ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’çµ„ã¿åˆã‚ã›ã¦
å®Ÿç¸¾å€¤ã¨ã®ä¹–é›¢ã‚’è©•ä¾¡ã—ã¾ã™ã€‚

ã€æ–¹æ³•â‘ ã€‘è¿‘éš£åŒ»ç™‚æ©Ÿé–¢ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ
  - OpenStreetMap (Overpass API) ã§è¿‘éš£ã‚¯ãƒªãƒ‹ãƒƒã‚¯ãƒ»ç—…é™¢ã‚’æ¤œç´¢
  - åšç”ŸåŠ´åƒçœãƒãƒ¼ã‚¿ãƒ«ã§å„æ–½è¨­ã®å¤–æ¥æ‚£è€…æ•°ã‚’ç…§ä¼š
  - è¨ºç™‚ç§‘åˆ¥å‡¦æ–¹ç®‹ç™ºè¡Œç‡ Ã— é™¢å¤–å‡¦æ–¹ç‡ Ã— ç«¶åˆè–¬å±€ã‚·ã‚§ã‚¢ã‹ã‚‰äºˆæ¸¬

ã€æ–¹æ³•â‘¡ã€‘å•†åœäººå£å‹•æ…‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ
  - å•†åœå†…äººå£æ¨è¨ˆï¼ˆå›½å‹¢èª¿æŸ»ãƒ™ãƒ¼ã‚¹ï¼‰
  - æ€§å¹´é½¢åˆ¥æœ‰ç—…ç‡ãƒ»å—è¨ºç‡ Ã— å‡¦æ–¹ç®‹ç™ºè¡Œç‡ Ã— è–¬å±€ã‚·ã‚§ã‚¢ã‹ã‚‰äºˆæ¸¬

ã€ç«¶åˆãƒãƒƒãƒ—ã€‘Folium (OpenStreetMap) ã§è¿‘éš£åŒ»ç™‚æ–½è¨­ãƒ»è–¬å±€ã‚’å¯è¦–åŒ–
"""

import math
import re
import time
import urllib.parse
from dataclasses import dataclass, field
from typing import Dict, List, Optional, Tuple

import folium
import requests
import streamlit as st
from bs4 import BeautifulSoup
from streamlit_folium import st_folium

# ---------------------------------------------------------------------------
# å®šæ•°ãƒ»çµ±è¨ˆãƒ‡ãƒ¼ã‚¿
# ---------------------------------------------------------------------------

PREFECTURES = [
    "åŒ—æµ·é“", "é’æ£®çœŒ", "å²©æ‰‹çœŒ", "å®®åŸçœŒ", "ç§‹ç”°çœŒ", "å±±å½¢çœŒ", "ç¦å³¶çœŒ",
    "èŒ¨åŸçœŒ", "æ ƒæœ¨çœŒ", "ç¾¤é¦¬çœŒ", "åŸ¼ç‰çœŒ", "åƒè‘‰çœŒ", "æ±äº¬éƒ½", "ç¥å¥ˆå·çœŒ",
    "æ–°æ½ŸçœŒ", "å¯Œå±±çœŒ", "çŸ³å·çœŒ", "ç¦äº•çœŒ", "å±±æ¢¨çœŒ", "é•·é‡çœŒ",
    "å²é˜œçœŒ", "é™å²¡çœŒ", "æ„›çŸ¥çœŒ", "ä¸‰é‡çœŒ",
    "æ»‹è³€çœŒ", "äº¬éƒ½åºœ", "å¤§é˜ªåºœ", "å…µåº«çœŒ", "å¥ˆè‰¯çœŒ", "å’Œæ­Œå±±çœŒ",
    "é³¥å–çœŒ", "å³¶æ ¹çœŒ", "å²¡å±±çœŒ", "åºƒå³¶çœŒ", "å±±å£çœŒ",
    "å¾³å³¶çœŒ", "é¦™å·çœŒ", "æ„›åª›çœŒ", "é«˜çŸ¥çœŒ",
    "ç¦å²¡çœŒ", "ä½è³€çœŒ", "é•·å´çœŒ", "ç†Šæœ¬çœŒ", "å¤§åˆ†çœŒ", "å®®å´çœŒ", "é¹¿å…å³¶çœŒ", "æ²–ç¸„çœŒ",
]
PREFECTURE_CODES: Dict[str, str] = {
    "åŒ—æµ·é“": "01", "é’æ£®çœŒ": "02", "å²©æ‰‹çœŒ": "03", "å®®åŸçœŒ": "04", "ç§‹ç”°çœŒ": "05",
    "å±±å½¢çœŒ": "06", "ç¦å³¶çœŒ": "07", "èŒ¨åŸçœŒ": "08", "æ ƒæœ¨çœŒ": "09", "ç¾¤é¦¬çœŒ": "10",
    "åŸ¼ç‰çœŒ": "11", "åƒè‘‰çœŒ": "12", "æ±äº¬éƒ½": "13", "ç¥å¥ˆå·çœŒ": "14", "æ–°æ½ŸçœŒ": "15",
    "å¯Œå±±çœŒ": "16", "çŸ³å·çœŒ": "17", "ç¦äº•çœŒ": "18", "å±±æ¢¨çœŒ": "19", "é•·é‡çœŒ": "20",
    "å²é˜œçœŒ": "21", "é™å²¡çœŒ": "22", "æ„›çŸ¥çœŒ": "23", "ä¸‰é‡çœŒ": "24", "æ»‹è³€çœŒ": "25",
    "äº¬éƒ½åºœ": "26", "å¤§é˜ªåºœ": "27", "å…µåº«çœŒ": "28", "å¥ˆè‰¯çœŒ": "29", "å’Œæ­Œå±±çœŒ": "30",
    "é³¥å–çœŒ": "31", "å³¶æ ¹çœŒ": "32", "å²¡å±±çœŒ": "33", "åºƒå³¶çœŒ": "34", "å±±å£çœŒ": "35",
    "å¾³å³¶çœŒ": "36", "é¦™å·çœŒ": "37", "æ„›åª›çœŒ": "38", "é«˜çŸ¥çœŒ": "39", "ç¦å²¡çœŒ": "40",
    "ä½è³€çœŒ": "41", "é•·å´çœŒ": "42", "ç†Šæœ¬çœŒ": "43", "å¤§åˆ†çœŒ": "44", "å®®å´çœŒ": "45",
    "é¹¿å…å³¶çœŒ": "46", "æ²–ç¸„çœŒ": "47",
}

# å…¨å›½çµ±è¨ˆï¼ˆåšç”ŸåŠ´åƒçœã€Œèª¿å‰¤åŒ»ç™‚è²»ã®å‹•å‘ã€2022å¹´åº¦ï¼‰
NATIONAL_STATS = {
    "total_prescriptions": 885_000_000,
    "total_pharmacies": 61_860,
    "average_per_year": 14_305,
    "median_estimate": 8_000,
    "daily_average": 44,
    "working_days": 305,
    "outpatient_rx_rate": 0.745,   # é™¢å¤–å‡¦æ–¹ç‡ï¼ˆå…¨å›½å¹³å‡ï¼‰
    "prescription_per_visit": 0.65, # å¤–æ¥1å—è¨ºã‚ãŸã‚Šå‡¦æ–¹ç®‹ç™ºè¡Œç‡
    "source": "åšç”ŸåŠ´åƒçœã€Œèª¿å‰¤åŒ»ç™‚è²»ã®å‹•å‘ã€2022å¹´åº¦",
}

# è¨ºç™‚ç§‘åˆ¥ å‡¦æ–¹ç®‹ç™ºè¡Œç‡ï¼ˆå¤–æ¥æ‚£è€…1äººã‚ãŸã‚Šï¼‰
# å‡ºå…¸: åšç”ŸåŠ´åƒçœã€Œå—ç™‚è¡Œå‹•èª¿æŸ»ã€ã€Œè–¬å±€ãƒ»è–¬å‰¤å¸«æ©Ÿèƒ½ã«é–¢ã™ã‚‹èª¿æŸ»ã€ç­‰ã‚ˆã‚Šæ¨è¨ˆ
SPECIALTY_RX_RATES: Dict[str, Tuple[float, str]] = {
    "ä¸€èˆ¬å†…ç§‘":     (0.76, "å†…ç§‘ç³»å…¨èˆ¬ï¼ˆæ…¢æ€§ç–¾æ‚£ãŒå¤šãé«˜å‡¦æ–¹ç‡ï¼‰"),
    "å¾ªç’°å™¨å†…ç§‘":   (0.88, "é«˜è¡€åœ§ãƒ»å¿ƒç–¾æ‚£ã¯ç¶™ç¶šå‡¦æ–¹ãŒå¤šã„"),
    "æ¶ˆåŒ–å™¨å†…ç§‘":   (0.74, "èƒƒè…¸ç–¾æ‚£ã¯è–¬ç‰©ç™‚æ³•ãŒä¸»ä½“"),
    "ç³–å°¿ç—…å†…ç§‘":   (0.90, "ã‚¤ãƒ³ã‚¹ãƒªãƒ³ãƒ»çµŒå£è¡€ç³–é™ä¸‹è–¬ã®ç¶™ç¶šå‡¦æ–¹"),
    "ç¥çµŒå†…ç§‘":     (0.82, "ç¥çµŒç–¾æ‚£ã¯è–¬ç‰©ç™‚æ³•ä¾å­˜åº¦é«˜"),
    "å‘¼å¸å™¨å†…ç§‘":   (0.78, "å–˜æ¯ãƒ»COPDç­‰ã®ç¶™ç¶šè–¬å¤šã„"),
    "å¤–ç§‘":         (0.58, "è¡“å¾Œãƒ•ã‚©ãƒ­ãƒ¼ã®å‡¦æ–¹ã¯æ¯”è¼ƒçš„å°‘ãªã„"),
    "æ•´å½¢å¤–ç§‘":     (0.72, "é®ç—›è–¬ãƒ»æ¹¿å¸ƒç­‰ã®å‡¦æ–¹å¤šã„"),
    "çš®è†šç§‘":       (0.64, "å¤–ç”¨è–¬ãƒ»æŠ—ã‚¢ãƒ¬ãƒ«ã‚®ãƒ¼è–¬ãªã©"),
    "çœ¼ç§‘":         (0.52, "ç‚¹çœ¼è–¬ã¯é™¢å†…äº¤ä»˜ã‚‚å¤šã„"),
    "è€³é¼»å’½å–‰ç§‘":   (0.58, "æŠ—èŒè–¬ç­‰ã®çŸ­æœŸå‡¦æ–¹ãŒå¤šã„"),
    "ç²¾ç¥ç§‘":       (0.85, "å‘ç²¾ç¥è–¬ã¯ç¶™ç¶šå‡¦æ–¹ãŒã»ã¼å¿…é ˆ"),
    "å°å…ç§‘":       (0.62, "æ€¥æ€§ç–¾æ‚£ãŒå¤šãå‡¦æ–¹ã¯æ¯”è¼ƒçš„å°‘ãªã„"),
    "ç”£å©¦äººç§‘":     (0.44, "å¥è¨ºãƒ»åˆ†å¨©ãŒå¤šãè–¬å‡¦æ–¹ã¯å°‘ãªã„"),
    "æ³Œå°¿å™¨ç§‘":     (0.70, "å‰ç«‹è…ºç–¾æ‚£ãƒ»éæ´»å‹•è†€èƒ±ç­‰ã®ç¶™ç¶šè–¬"),
    "ãƒªãƒãƒ“ãƒªç§‘":   (0.40, "ãƒªãƒãƒ“ãƒªä¸­å¿ƒã§å‡¦æ–¹ã¯å°‘ãªã„"),
    "ä¸æ˜/ãã®ä»–":  (0.68, "å…¨è¨ºç™‚ç§‘å¹³å‡å€¤ã‚’ä½¿ç”¨"),
}

# OSM ã® healthcare:speciality ã‚¿ã‚° â†’ æ—¥æœ¬èªè¨ºç™‚ç§‘ãƒãƒƒãƒ”ãƒ³ã‚°
OSM_SPECIALTY_MAP: Dict[str, str] = {
    "general": "ä¸€èˆ¬å†…ç§‘", "general_practitioner": "ä¸€èˆ¬å†…ç§‘", "internal": "ä¸€èˆ¬å†…ç§‘",
    "cardiology": "å¾ªç’°å™¨å†…ç§‘",
    "gastroenterology": "æ¶ˆåŒ–å™¨å†…ç§‘",
    "diabetes": "ç³–å°¿ç—…å†…ç§‘", "endocrinology": "ç³–å°¿ç—…å†…ç§‘",
    "neurology": "ç¥çµŒå†…ç§‘",
    "pulmonology": "å‘¼å¸å™¨å†…ç§‘", "respiratory": "å‘¼å¸å™¨å†…ç§‘",
    "surgery": "å¤–ç§‘",
    "orthopaedics": "æ•´å½¢å¤–ç§‘", "orthopedics": "æ•´å½¢å¤–ç§‘",
    "dermatology": "çš®è†šç§‘",
    "ophthalmology": "çœ¼ç§‘",
    "otolaryngology": "è€³é¼»å’½å–‰ç§‘", "ent": "è€³é¼»å’½å–‰ç§‘",
    "psychiatry": "ç²¾ç¥ç§‘", "mental_health": "ç²¾ç¥ç§‘",
    "paediatrics": "å°å…ç§‘", "pediatrics": "å°å…ç§‘",
    "gynaecology": "ç”£å©¦äººç§‘", "obstetrics": "ç”£å©¦äººç§‘",
    "urology": "æ³Œå°¿å™¨ç§‘",
    "rehabilitation": "ãƒªãƒãƒ“ãƒªç§‘",
}

# å¹´é½¢å±¤åˆ¥ å¤–æ¥å—è¨ºç‡ï¼ˆå›/å¹´/äººï¼‰åšç”ŸåŠ´åƒçœã€Œæ‚£è€…èª¿æŸ»ã€2020å¹´
VISIT_RATE_BY_AGE: Dict[str, float] = {
    "0-14æ­³":  9.8,
    "15-44æ­³": 7.2,
    "45-64æ­³": 11.3,
    "65-74æ­³": 19.2,
    "75æ­³ä»¥ä¸Š": 22.1,
}

# æ—¥æœ¬ã®å¹´é½¢åˆ†å¸ƒï¼ˆ2020å¹´å›½å‹¢èª¿æŸ»ï¼‰
AGE_DISTRIBUTION: Dict[str, float] = {
    "0-14æ­³":  0.119,
    "15-44æ­³": 0.342,
    "45-64æ­³": 0.256,
    "65-74æ­³": 0.145,
    "75æ­³ä»¥ä¸Š": 0.138,
}

# å•†åœã®äººå£å¯†åº¦é¸æŠè‚¢ï¼ˆäºº/kmÂ²ï¼‰
AREA_DENSITY_OPTIONS: Dict[str, int] = {
    "è¶…é«˜å¯†åº¦ï¼ˆæ±äº¬23åŒºãƒ»å¤§é˜ªå¸‚ä¸­å¿ƒç­‰ï¼‰": 15_000,
    "é«˜å¯†åº¦ï¼ˆæ”¿ä»¤æŒ‡å®šéƒ½å¸‚ä¸­å¿ƒéƒ¨ï¼‰":      8_000,
    "ä¸­é«˜å¯†åº¦ï¼ˆåœ°æ–¹éƒ½å¸‚ä¸­å¿ƒéƒ¨ï¼‰":        3_000,
    "ä¸­å¯†åº¦ï¼ˆéƒŠå¤–ä½å®…åœ°ï¼‰":             1_500,
    "ä½å¯†åº¦ï¼ˆåœ°æ–¹å¸‚è¡—åœ°ï¼‰":             500,
    "è¶…ä½å¯†åº¦ï¼ˆè¾²æ‘ãƒ»å±±é–“éƒ¨ï¼‰":          100,
}

# å¤§æ‰‹ãƒã‚§ãƒ¼ãƒ³è–¬å±€ï¼ˆç«¶åˆåˆ¤å®šã«ä½¿ç”¨ï¼‰
MAJOR_CHAINS = [
    "ã‚¦ã‚¨ãƒ«ã‚·ã‚¢", "ãƒ„ãƒ«ãƒ", "ãƒãƒ„ãƒ¢ãƒˆã‚­ãƒ¨ã‚·", "ãƒãƒ„ã‚­ãƒ¨", "ã‚¹ã‚®è–¬å±€",
    "ã‚³ã‚¹ãƒ¢ã‚¹è–¬å“", "ã‚¯ãƒªã‚¨ã‚¤ãƒˆ", "ã‚µãƒ³ãƒ‰ãƒ©ãƒƒã‚°", "ã‚«ãƒ¯ãƒè–¬å“",
    "æ—¥æœ¬èª¿å‰¤", "ã‚¯ã‚ªãƒ¼ãƒ«", "ã‚¢ã‚¤ãƒ³", "ãƒ•ã‚¡ãƒ¼ãƒãƒ©ã‚¤ã‚º", "ç·åˆãƒ¡ãƒ‡ã‚£ã‚«ãƒ«",
]

# ---------------------------------------------------------------------------
# ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹
# ---------------------------------------------------------------------------

@dataclass
class PharmacyCandidate:
    name: str
    address: str
    href: str
    pref_cd: str = ""
    kikan_cd: str = ""

@dataclass
class NearbyFacility:
    name: str
    facility_type: str       # "hospital" | "clinic" | "pharmacy"
    lat: float
    lon: float
    distance_m: float        # å¯¾è±¡è–¬å±€ã‹ã‚‰ã®ç›´ç·šè·é›¢ï¼ˆmï¼‰
    specialty: str = "ä¸æ˜/ãã®ä»–"
    daily_outpatients: int = 0
    beds: int = 0
    has_inhouse_pharmacy: bool = False
    has_gate_pharmacy: bool = False  # é–€å‰è–¬å±€ãŒå­˜åœ¨ã™ã‚‹ã‹
    osm_tags: Dict = field(default_factory=dict)
    mhlw_annual_outpatients: Optional[int] = None

@dataclass
class PredictionResult:
    method_name: str
    annual_rx: int
    min_val: int
    max_val: int
    confidence: str
    daily_rx: int
    breakdown: List[Dict] = field(default_factory=list)
    methodology: List[str] = field(default_factory=list)
    references: List[Dict] = field(default_factory=list)

@dataclass
class FullAnalysis:
    pharmacy_name: str
    pharmacy_address: str
    pharmacy_lat: float
    pharmacy_lon: float
    mhlw_annual_rx: Optional[int]
    mhlw_source_url: str
    method1: Optional[PredictionResult]
    method2: Optional[PredictionResult]
    nearby_medical: List[NearbyFacility]
    nearby_pharmacies: List[NearbyFacility]
    search_log: List[str] = field(default_factory=list)


# ---------------------------------------------------------------------------
# 1. ã‚¸ã‚ªã‚³ãƒ¼ãƒ€ãƒ¼ï¼ˆNominatim / OpenStreetMapï¼‰
# ---------------------------------------------------------------------------

class GeocoderService:
    """ä½æ‰€ â†’ ç·¯åº¦çµŒåº¦å¤‰æ›ï¼ˆNominatim APIã‚’ä½¿ç”¨ãƒ»ç„¡æ–™ãƒ»APIã‚­ãƒ¼ä¸è¦ï¼‰"""

    URL = "https://nominatim.openstreetmap.org/search"

    def geocode(self, address: str) -> Tuple[Optional[float], Optional[float], str]:
        """
        ä½æ‰€ã‚’ç·¯åº¦çµŒåº¦ã«å¤‰æ›ã™ã‚‹ã€‚

        Returns:
            (lat, lon, normalized_address) or (None, None, error_message)
        """
        if not address:
            return None, None, "ä½æ‰€ãŒç©ºã§ã™"

        # ã€ŒGoogleãƒãƒƒãƒ—ã§è¦‹ã‚‹ã€ãªã©ã®ä½™åˆ†ãªãƒ†ã‚­ã‚¹ãƒˆã‚’é™¤å»
        clean_address = re.sub(r"Googleãƒãƒƒãƒ—.*|Google Map.*", "", address).strip()
        clean_address = re.sub(r"\s+", " ", clean_address)

        try:
            # æ—¥æœ¬èªä½æ‰€ã¯ãã®ã¾ã¾æ¸¡ã™ï¼ˆNominatimã¯å¯¾å¿œæ¸ˆã¿ï¼‰
            params = {
                "q": clean_address + ", æ—¥æœ¬",
                "format": "json",
                "limit": 1,
                "addressdetails": 1,
            }
            headers = {"User-Agent": "PharmacyRxPredictorV2/1.0 (research tool)"}
            r = requests.get(self.URL, params=params, headers=headers, timeout=10)
            r.raise_for_status()
            data = r.json()

            if not data:
                # ä½æ‰€ã‚’çŸ­ç¸®ã—ã¦å†è©¦è¡Œ
                parts = clean_address.split()
                if len(parts) > 2:
                    short_addr = " ".join(parts[:3])
                    params["q"] = short_addr + ", æ—¥æœ¬"
                    r = requests.get(self.URL, params=params, headers=headers, timeout=10)
                    data = r.json()

            if data:
                lat = float(data[0]["lat"])
                lon = float(data[0]["lon"])
                display = data[0].get("display_name", clean_address)
                return lat, lon, display

            return None, None, f"ä½æ‰€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {clean_address}"

        except requests.Timeout:
            return None, None, "ã‚¸ã‚ªã‚³ãƒ¼ãƒ€ãƒ¼ã¸ã®æ¥ç¶šã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ"
        except Exception as e:
            return None, None, f"ã‚¸ã‚ªã‚³ãƒ¼ãƒ€ãƒ¼ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}"


# ---------------------------------------------------------------------------
# 2. è¿‘éš£æ–½è¨­æ¤œç´¢ï¼ˆOverpass API / OpenStreetMapï¼‰
# ---------------------------------------------------------------------------

class OverpassSearcher:
    """OpenStreetMap ã® Overpass API ã§è¿‘éš£åŒ»ç™‚æ–½è¨­ãƒ»è–¬å±€ã‚’æ¤œç´¢ï¼ˆç„¡æ–™ãƒ»APIã‚­ãƒ¼ä¸è¦ï¼‰"""

    URL = "https://overpass-api.de/api/interpreter"

    def search_nearby(
        self, lat: float, lon: float, radius: int = 500
    ) -> Tuple[List[NearbyFacility], List[NearbyFacility], str]:
        """
        æŒ‡å®šåº§æ¨™ã®åŠå¾„radius(m)å†…ã®åŒ»ç™‚æ–½è¨­ã¨è–¬å±€ã‚’å–å¾—ã™ã‚‹ã€‚

        Returns:
            (medical_facilities, pharmacies, status_message)
        """
        query = f"""
[out:json][timeout:30];
(
  node["amenity"~"^(hospital|clinic|doctors)$"](around:{radius},{lat},{lon});
  way["amenity"~"^(hospital|clinic|doctors)$"](around:{radius},{lat},{lon});
  node["healthcare"~"^(hospital|clinic|doctor|centre)$"](around:{radius},{lat},{lon});
  way["healthcare"~"^(hospital|clinic|doctor|centre)$"](around:{radius},{lat},{lon});
  node["amenity"="pharmacy"](around:{radius},{lat},{lon});
  way["amenity"="pharmacy"](around:{radius},{lat},{lon});
);
out center tags;
"""
        try:
            r = requests.post(self.URL, data={"data": query}, timeout=30)
            r.raise_for_status()
            data = r.json()
        except requests.Timeout:
            return [], [], "Overpass APIã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼ˆ30ç§’ï¼‰"
        except Exception as e:
            return [], [], f"Overpass APIã‚¨ãƒ©ãƒ¼: {e}"

        medical: List[NearbyFacility] = []
        pharmacies: List[NearbyFacility] = []

        for elem in data.get("elements", []):
            tags = elem.get("tags", {})
            name = tags.get("name", tags.get("name:ja", "åç§°ä¸æ˜"))
            if not name or name == "åç§°ä¸æ˜":
                continue

            # åº§æ¨™
            if elem["type"] == "node":
                e_lat, e_lon = elem.get("lat", 0), elem.get("lon", 0)
            else:
                center = elem.get("center", {})
                e_lat, e_lon = center.get("lat", 0), center.get("lon", 0)

            if not (e_lat and e_lon):
                continue

            dist = self._haversine(lat, lon, e_lat, e_lon)

            amenity = tags.get("amenity", "")
            healthcare = tags.get("healthcare", "")
            is_pharmacy = amenity == "pharmacy"

            if is_pharmacy:
                pharmacies.append(NearbyFacility(
                    name=name,
                    facility_type="pharmacy",
                    lat=e_lat, lon=e_lon,
                    distance_m=dist,
                    osm_tags=tags,
                ))
                continue

            # åŒ»ç™‚æ©Ÿé–¢
            ftype = "hospital" if (
                amenity == "hospital"
                or healthcare == "hospital"
                or int(tags.get("beds", 0) or 0) >= 20
            ) else "clinic"

            # è¨ºç™‚ç§‘
            specialty_raw = tags.get("healthcare:speciality", tags.get("specialty", ""))
            specialty = OSM_SPECIALTY_MAP.get(specialty_raw.lower(), "ä¸€èˆ¬å†…ç§‘") if specialty_raw else "ä¸€èˆ¬å†…ç§‘"

            # é™¢å†…è–¬å±€ãƒ•ãƒ©ã‚°
            has_inhouse = tags.get("pharmacy", "") in ["yes", "dispensing"]

            # ç—…åºŠæ•°
            beds = int(tags.get("beds", 0) or 0)

            # æ—¥æ¬¡å¤–æ¥æ‚£è€…æ¨è¨ˆ
            daily_op = self._estimate_daily_outpatients(ftype, beds, tags)

            medical.append(NearbyFacility(
                name=name,
                facility_type=ftype,
                lat=e_lat, lon=e_lon,
                distance_m=dist,
                specialty=specialty,
                daily_outpatients=daily_op,
                beds=beds,
                has_inhouse_pharmacy=has_inhouse,
                osm_tags=tags,
            ))

        medical.sort(key=lambda x: x.distance_m)
        pharmacies.sort(key=lambda x: x.distance_m)

        return medical, pharmacies, f"åŒ»ç™‚æ©Ÿé–¢{len(medical)}ä»¶ãƒ»è–¬å±€{len(pharmacies)}ä»¶ã‚’å–å¾—"

    @staticmethod
    def _haversine(lat1: float, lon1: float, lat2: float, lon2: float) -> float:
        """2ç‚¹é–“ã®è·é›¢ã‚’ãƒ¡ãƒ¼ãƒˆãƒ«ã§è¨ˆç®—"""
        R = 6_371_000
        phi1, phi2 = math.radians(lat1), math.radians(lat2)
        dphi = math.radians(lat2 - lat1)
        dlam = math.radians(lon2 - lon1)
        a = math.sin(dphi / 2) ** 2 + math.cos(phi1) * math.cos(phi2) * math.sin(dlam / 2) ** 2
        return R * 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))

    @staticmethod
    def _estimate_daily_outpatients(ftype: str, beds: int, tags: Dict) -> int:
        """æ–½è¨­è¦æ¨¡ã‹ã‚‰1æ—¥å¤–æ¥æ‚£è€…æ•°ã‚’æ¨è¨ˆ"""
        if ftype == "hospital":
            if beds >= 300:   return 1_000
            if beds >= 100:   return 400
            if beds >= 20:    return 150
            return 150
        else:  # clinic
            # è¨ºç™‚ç§‘ã‚„è¦æ¨¡ã‹ã‚‰æ¨è¨ˆ
            doctors = int(tags.get("staff:count", 0) or 0)
            if doctors >= 3:  return 100
            if doctors >= 2:  return 60
            return 35  # ä¸€èˆ¬çš„ãªå€‹äººã‚¯ãƒªãƒ‹ãƒƒã‚¯


# ---------------------------------------------------------------------------
# 3. åšç”ŸåŠ´åƒçœã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼ï¼ˆv1ã‹ã‚‰ç¶™æ‰¿ãƒ»åŒ»ç™‚æ©Ÿé–¢æ¤œç´¢ã‚’è¿½åŠ ï¼‰
# ---------------------------------------------------------------------------

class MHLWScraper:
    """åšç”ŸåŠ´åƒçœ åŒ»ç™‚æƒ…å ±ãƒãƒƒãƒˆï¼ˆãƒŠãƒ“ã‚¤ï¼‰ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼"""

    DOMAIN = "https://www.iryou.teikyouseido.mhlw.go.jp"
    BASE   = DOMAIN + "/znk-web"

    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            "User-Agent": (
                "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) "
                "AppleWebKit/537.36 Chrome/121.0.0.0 Safari/537.36"
            ),
            "Accept-Language": "ja-JP,ja;q=0.9",
        })
        self._initialized = False

    def initialize_session(self) -> bool:
        try:
            r = self.session.get(
                f"{self.BASE}/juminkanja/S2300/initialize",
                timeout=15, allow_redirects=True,
            )
            self._initialized = r.status_code == 200
            return self._initialized
        except Exception:
            return False

    def search_pharmacy_candidates(
        self, keyword: str, pref_code: str = "", max_pages: int = 3
    ) -> Tuple[List[PharmacyCandidate], int, str]:
        """è–¬å±€å€™è£œã‚’æ¤œç´¢ï¼ˆsjk=2ï¼‰"""
        return self._search_candidates(keyword, pref_code, max_pages, sjk="2")

    def search_medical_candidates(
        self, keyword: str, pref_code: str = ""
    ) -> Tuple[List[PharmacyCandidate], int, str]:
        """åŒ»ç™‚æ©Ÿé–¢å€™è£œã‚’æ¤œç´¢ï¼ˆsjk=1ï¼‰"""
        return self._search_candidates(keyword, pref_code, max_pages=1, sjk="1")

    def _search_candidates(
        self, keyword: str, pref_code: str, max_pages: int, sjk: str
    ) -> Tuple[List[PharmacyCandidate], int, str]:
        if not self._initialized:
            self.initialize_session()

        try:
            r = self.session.get(
                f"{self.BASE}/juminkanja/S2300/yakkyokuSearch",
                params={"yakkyokuKeyword": keyword, "yakkyokuKeyword2": "", "searchJudgeKbn": "2"},
                headers={"ajaxFlag": "true"}, timeout=12,
            )
            if r.status_code != 200:
                return [], 0, f"æ¤œç´¢å¤±æ•— HTTP {r.status_code}"
            j = r.json()
            if j.get("code") != "0":
                return [], 0, "æ¤œç´¢ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³å¤±æ•—"
        except Exception as e:
            return [], 0, f"æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}"

        all_candidates: List[PharmacyCandidate] = []
        total_count = 0
        encoded = urllib.parse.quote(keyword)

        for page in range(max_pages):
            params = {"sjk": sjk, "page": str(page), "size": "20", "sortNo": "1"}
            if pref_code:
                params["prefCd"] = pref_code
            try:
                r2 = self.session.get(
                    f"{self.BASE}/juminkanja/S2400/initialize/{encoded}/",
                    params=params, timeout=15,
                )
                if r2.status_code != 200:
                    break
                candidates, total = self._parse_candidate_list(r2.text, sjk)
                if page == 0:
                    total_count = total
                all_candidates.extend(candidates)
                if len(candidates) == 0 or len(all_candidates) >= total_count:
                    break
                time.sleep(0.3)
            except Exception:
                break

        return all_candidates, total_count, f"{len(all_candidates)}ä»¶å–å¾—ï¼ˆå…¨{total_count}ä»¶ï¼‰"

    def _parse_candidate_list(
        self, html: str, sjk: str = "2"
    ) -> Tuple[List[PharmacyCandidate], int]:
        soup = BeautifulSoup(html, "html.parser")
        candidates = []
        total = 0
        cnt_match = re.search(r"(\d{1,6})\s*ä»¶", soup.get_text())
        if cnt_match:
            total = int(cnt_match.group(1))

        for item in soup.find_all("div", class_="item"):
            h3 = item.find("h3", class_="name")
            if not h3:
                continue
            link = h3.find("a", href=True)
            if not link:
                continue
            name = link.get_text(strip=True)
            href = link.get("href", "")
            if not href:
                continue
            if href.startswith("/"):
                href = self.DOMAIN + href

            parsed = urllib.parse.urlparse(href)
            qp = dict(urllib.parse.parse_qsl(parsed.query))
            pref_cd = qp.get("prefCd", "")
            kikan_cd = qp.get("kikanCd", "")

            address = ""
            for dl in item.find_all("dl"):
                dt = dl.find("dt")
                if not dt:
                    continue
                img = dt.find("img")
                dt_text = dt.get_text(strip=True)
                if (img and "ä½æ‰€" in img.get("alt", "")) or any(
                    kw in dt_text for kw in ["ä½æ‰€", "æ‰€åœ¨åœ°"]
                ):
                    dd = dl.find("dd")
                    if dd:
                        for a in dd.find_all("a"):
                            a.decompose()
                        raw = dd.get_text(strip=True)
                        cleaned = re.sub(r"ã€’\s*\d{3}[-ï¼]\d{4}\s*", "", raw)
                        address = re.sub(r"\s+", " ", cleaned).strip()[:60]
                    break

            if name:
                candidates.append(PharmacyCandidate(
                    name=name, address=address, href=href,
                    pref_cd=pref_cd, kikan_cd=kikan_cd,
                ))

        return candidates, max(total, len(candidates))

    def get_pharmacy_detail(
        self, candidate: PharmacyCandidate
    ) -> Tuple[Optional[Dict], str]:
        """è–¬å±€è©³ç´°ï¼ˆå‡¦æ–¹ç®‹æ•°ãƒ»ä½æ‰€ï¼‰ã‚’å–å¾—"""
        if not self._initialized:
            self.initialize_session()

        if candidate.pref_cd and candidate.kikan_cd:
            url = (
                f"{self.BASE}/juminkanja/S2430/initialize"
                f"?prefCd={candidate.pref_cd}&kikanCd={candidate.kikan_cd}&kikanKbn=5"
            )
        else:
            url = candidate.href

        try:
            r = self.session.get(url, timeout=15)
            if r.status_code != 200:
                return None, f"HTTP {r.status_code}"
            data = self._parse_pharmacy_detail(r.text)
            data["source_url"] = url
            return data, "OK"
        except Exception as e:
            return None, str(e)

    def _parse_pharmacy_detail(self, html: str) -> Dict:
        soup = BeautifulSoup(html, "html.parser")
        data: Dict = {}
        fields: Dict[str, str] = {}

        for row in soup.find_all("tr"):
            cells = row.find_all(["th", "td"])
            if len(cells) >= 2:
                key = cells[0].get_text(strip=True)
                val = cells[1].get_text(strip=True)
                if key:
                    fields[key] = val

        for dl in soup.find_all("dl"):
            dts = dl.find_all("dt")
            dds = dl.find_all("dd")
            for dt, dd in zip(dts, dds):
                key = dt.get_text(strip=True)
                val = dd.get_text(strip=True)
                if key:
                    fields[key] = val

        data["all_fields"] = fields

        # ä½æ‰€å–å¾—
        for k, v in fields.items():
            if "æ‰€åœ¨åœ°" in k and "ãƒ•ãƒªã‚¬ãƒŠ" not in k and "è‹±èª" not in k:
                clean = re.sub(r"Googleãƒãƒƒãƒ—.*", "", v).strip()
                data["address"] = clean
                break

        # ç·å–æ‰±å‡¦æ–¹ç®‹æ•°ï¼ˆæœ€å„ªå…ˆï¼‰
        rx_annual = None
        rx_period = None
        for field_key, field_val in fields.items():
            if "ç·å–æ‰±å‡¦æ–¹ç®‹æ•°" in field_key:
                nums = re.findall(r"[\d,]+", field_val)
                if nums:
                    try:
                        n = int(nums[0].replace(",", ""))
                        if n > 0:
                            rx_annual = n
                            rx_period = "å¹´é–“å®Ÿç¸¾ï¼ˆå‰å¹´1å¹´é–“ã®å–æ‰±å‡¦æ–¹ç®‹æšæ•°ï¼‰"
                            break
                    except (ValueError, OverflowError):
                        pass

        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        if rx_annual is None:
            full_text = soup.get_text(separator=" ")
            for pat, period, mult in [
                (r"ç·å–æ‰±å‡¦æ–¹ç®‹æ•°[^\d]*(\d{1,3}(?:,\d{3})*|\d{4,})\s*ä»¶", "annual", 1.0),
                (r"é€±\s*å¹³å‡[^\d]{0,15}(\d{1,4})\s*(?:å›|æš)", "weekly", 52.14),
                (r"å¹´é–“[^\d]{0,15}(\d{1,6}(?:,\d{3})*)\s*(?:å›|ä»¶)", "annual", 1.0),
            ]:
                m = re.search(pat, full_text, re.DOTALL)
                if m:
                    try:
                        n = int(m.group(1).replace(",", ""))
                        if n > 0:
                            rx_annual = int(n * mult)
                            rx_period = "é€±å¹³å‡â†’å¹´æ›ç®—" if period == "weekly" else "å¹´é–“å®Ÿç¸¾"
                            break
                    except (ValueError, OverflowError):
                        pass

        data["prescriptions_annual"] = rx_annual
        data["prescription_period_label"] = rx_period
        return data

    def get_medical_outpatient_data(
        self, facility_name: str, pref_code: str = ""
    ) -> Optional[int]:
        """è¿‘éš£åŒ»ç™‚æ©Ÿé–¢ã®å¤–æ¥æ‚£è€…æ•°ã‚’å–å¾—ï¼ˆsjk=1ï¼‰"""
        if not self._initialized:
            self.initialize_session()
        candidates, _, _ = self.search_medical_candidates(facility_name, pref_code)
        if not candidates:
            return None

        # åç§°ãŒæœ€ã‚‚è¿‘ã„å€™è£œã‚’é¸ã¶
        best = None
        for c in candidates[:3]:
            if facility_name[:4] in c.name or c.name[:4] in facility_name:
                best = c
                break
        if best is None and candidates:
            best = candidates[0]

        try:
            url = best.href
            r = self.session.get(url, timeout=12)
            if r.status_code != 200:
                return None
            soup = BeautifulSoup(r.text, "html.parser")
            fields: Dict[str, str] = {}
            for row in soup.find_all("tr"):
                cells = row.find_all(["th", "td"])
                if len(cells) >= 2:
                    fields[cells[0].get_text(strip=True)] = cells[1].get_text(strip=True)

            for k, v in fields.items():
                if "å¤–æ¥" in k and ("æ‚£è€…" in k or "æ•°" in k):
                    nums = re.findall(r"[\d,]+", v)
                    if nums:
                        return int(nums[0].replace(",", ""))
        except Exception:
            pass
        return None


# ---------------------------------------------------------------------------
# 4. æ–¹æ³•â‘  è¿‘éš£åŒ»ç™‚æ©Ÿé–¢ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ
# ---------------------------------------------------------------------------

class Method1Predictor:
    """
    è¿‘éš£åŒ»ç™‚æ–½è¨­ã®å¤–æ¥æ‚£è€…æ•°ã‹ã‚‰å‡¦æ–¹ç®‹æµå…¥é‡ã‚’äºˆæ¸¬ã™ã‚‹ã€‚

    ãƒ­ã‚¸ãƒƒã‚¯:
      å„åŒ»ç™‚æ–½è¨­ã«ã¤ã„ã¦:
        1. å¤–æ¥æ‚£è€…æ•° Ã— è¨ºç™‚ç§‘åˆ¥å‡¦æ–¹ç®‹ç™ºè¡Œç‡ = å‡¦æ–¹ç®‹ç™ºè¡Œæ•°
        2. Ã— é™¢å¤–å‡¦æ–¹ç‡(0.745) = é™¢å¤–å‡¦æ–¹ç®‹æ•°
        3. Ã— å½“è–¬å±€ã‚·ã‚§ã‚¢ï¼ˆè·é›¢ãƒ»ç«¶åˆæ•°ã«åŸºã¥ãï¼‰ = å½“è–¬å±€æµå…¥å‡¦æ–¹ç®‹æ•°
      å…¨æ–½è¨­ã®åˆè¨ˆ Ã— å¹´é–“ç¨¼åƒæ—¥æ•° = å¹´é–“å‡¦æ–¹ç®‹å—ä»˜æšæ•°ï¼ˆæ¨è¨ˆï¼‰
    """

    OUTPATIENT_RX_RATE = NATIONAL_STATS["outpatient_rx_rate"]

    def predict(
        self,
        pharmacy_lat: float,
        pharmacy_lon: float,
        medical_facilities: List[NearbyFacility],
        competing_pharmacies: List[NearbyFacility],
    ) -> PredictionResult:
        breakdown = []
        total_daily_rx = 0.0
        methodology = [
            "### æ–¹æ³•â‘  ãƒ­ã‚¸ãƒƒã‚¯: è¿‘éš£åŒ»ç™‚æ©Ÿé–¢ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ",
            "",
            "**ç®—å‡ºå¼**:",
            "ã€€å„æ–½è¨­ã®å¤–æ¥æ‚£è€…æ•° Ã— è¨ºç™‚ç§‘åˆ¥å‡¦æ–¹ç®‹ç™ºè¡Œç‡",
            "ã€€Ã— é™¢å¤–å‡¦æ–¹ç‡ï¼ˆ0.745ï¼‰Ã— å½“è–¬å±€é›†å®¢ã‚·ã‚§ã‚¢",
            "ã€€â†’ æ–½è¨­ã”ã¨ã®å½“è–¬å±€ã¸ã®æ—¥æ¬¡æµå…¥å‡¦æ–¹ç®‹æ•°ã‚’åˆè¨ˆ",
            "",
            f"**å¯¾è±¡åŠå¾„**: 500mä»¥å†…ã®åŒ»ç™‚æ–½è¨­ {len(medical_facilities)}ä»¶",
            "",
        ]

        for fac in medical_facilities:
            if fac.daily_outpatients == 0:
                continue

            # é™¢å¤–å‡¦æ–¹ç®‹ç™ºè¡Œæ•°/æ—¥
            rx_rate, rx_note = SPECIALTY_RX_RATES.get(
                fac.specialty, SPECIALTY_RX_RATES["ä¸æ˜/ãã®ä»–"]
            )
            daily_outpatient_rx = fac.daily_outpatients * rx_rate * self.OUTPATIENT_RX_RATE

            # é™¢å†…è–¬å±€ãŒã‚ã‚‹å ´åˆã¯é™¢å¤–å‡¦æ–¹ç‡ã‚’è£œæ­£
            if fac.has_inhouse_pharmacy:
                daily_outpatient_rx *= 0.6  # é™¢å†…å‡¦æ–¹ãŒå¢—ãˆã‚‹

            # å½“è–¬å±€ã¸ã®é›†å®¢ã‚·ã‚§ã‚¢æ¨è¨ˆ
            share, share_reason = self._calc_pharmacy_share(
                fac, pharmacy_lat, pharmacy_lon, competing_pharmacies
            )

            # é–€å‰è–¬å±€ï¼ˆä»–è–¬å±€ï¼‰ãŒã„ã‚‹å ´åˆã®è£œæ­£
            if fac.has_gate_pharmacy:
                share *= 0.4
                share_reason += "ï¼ˆæ—¢å­˜é–€å‰è–¬å±€ã‚ã‚Š â†’ ã‚·ã‚§ã‚¢å¤§å¹…å‰²å¼•ï¼‰"

            daily_flow = daily_outpatient_rx * share

            breakdown.append({
                "æ–½è¨­å":         fac.name,
                "ã‚¿ã‚¤ãƒ—":         "ç—…é™¢" if fac.facility_type == "hospital" else "ã‚¯ãƒªãƒ‹ãƒƒã‚¯",
                "è·é›¢":           f"{fac.distance_m:.0f}m",
                "è¨ºç™‚ç§‘":         fac.specialty,
                "å¤–æ¥æ‚£è€…/æ—¥":    fac.daily_outpatients,
                "å‡¦æ–¹ç®‹ç™ºè¡Œç‡":   f"{rx_rate:.0%}",
                "é™¢å¤–å‡¦æ–¹ç®‹/æ—¥":  round(daily_outpatient_rx),
                "å½“è–¬å±€ã‚·ã‚§ã‚¢":   f"{share:.1%}",
                "ã‚·ã‚§ã‚¢æ ¹æ‹ ":     share_reason,
                "å½“è–¬å±€æµå…¥/æ—¥":  round(daily_flow),
            })

            total_daily_rx += daily_flow
            methodology.append(
                f"**{fac.name}** ({fac.distance_m:.0f}m): "
                f"å¤–æ¥{fac.daily_outpatients}äºº/æ—¥ Ã— {rx_rate:.0%} Ã— é™¢å¤–ç‡{self.OUTPATIENT_RX_RATE:.1%} "
                f"Ã— å½“è–¬å±€{share:.0%} = {daily_flow:.1f}æš/æ—¥"
            )

        annual_est = int(total_daily_rx * NATIONAL_STATS["working_days"])
        min_val = int(annual_est * 0.6)
        max_val = int(annual_est * 1.8)

        methodology += [
            "",
            f"**åˆè¨ˆ**: {total_daily_rx:.1f}æš/æ—¥ Ã— {NATIONAL_STATS['working_days']}æ—¥ = **{annual_est:,}æš/å¹´**",
            "",
            "**ã‚·ã‚§ã‚¢è¨ˆç®—ã®è€ƒãˆæ–¹**:",
            "  - æ–½è¨­ã‹ã‚‰50mä»¥å†…ã‹ã¤ç«¶åˆãªã—: 70-80%ï¼ˆå®Ÿè³ªçš„ãªé–€å‰è–¬å±€ï¼‰",
            "  - æ–½è¨­ã‹ã‚‰200mä»¥å†…: 30-50%ï¼ˆä¸»è¦ãªé¸æŠè‚¢ï¼‰",
            "  - æ–½è¨­ã‹ã‚‰500mä»¥å†…: 10-20%ï¼ˆè¤‡æ•°ã®é¸æŠè‚¢ã®ä¸€ã¤ï¼‰",
            "  - ç«¶åˆè–¬å±€1ä»¶ã”ã¨ã«ã‚·ã‚§ã‚¢ã‚’æŒ‰åˆ†æ¸›ç®—",
            "",
            "**æ³¨æ„äº‹é …**:",
            "  - å¤–æ¥æ‚£è€…æ•°ã¯æ–½è¨­è¦æ¨¡ã‹ã‚‰æ¨è¨ˆï¼ˆOSMã‚¿ã‚°ã«åŸºã¥ãï¼‰",
            "  - MHLWãƒãƒ¼ã‚¿ãƒ«ã§å®Ÿéš›ã®å¤–æ¥æ‚£è€…æ•°ãŒå–å¾—ã§ããŸæ–½è¨­ã¯å®Ÿç¸¾å€¤ã‚’ä½¿ç”¨",
            "  - é™¢å†…è–¬å±€ã®æœ‰ç„¡ã¯OSMã‚¿ã‚° 'pharmacy=yes' ã‹ã‚‰åˆ¤å®š",
        ]

        confidence = "medium" if medical_facilities else "low"
        if not medical_facilities:
            methodology.append("  âš  è¿‘éš£ã«åŒ»ç™‚æ–½è¨­ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚çµ±è¨ˆæ¨è¨ˆå€¤ã«ç½®ãæ›ãˆã¾ã™ã€‚")
            annual_est = NATIONAL_STATS["median_estimate"]
            min_val = 2_000
            max_val = 20_000

        return PredictionResult(
            method_name="æ–¹æ³•â‘ : è¿‘éš£åŒ»ç™‚æ©Ÿé–¢ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ",
            annual_rx=annual_est,
            min_val=min_val,
            max_val=max_val,
            confidence=confidence,
            daily_rx=int(total_daily_rx),
            breakdown=breakdown,
            methodology=methodology,
            references=[
                {
                    "name": "åšç”ŸåŠ´åƒçœã€Œå—ç™‚è¡Œå‹•èª¿æŸ»ã€",
                    "desc": "è¨ºç™‚ç§‘åˆ¥å‡¦æ–¹ç®‹ç™ºè¡Œç‡ï¼ˆå¤–æ¥æ‚£è€…1äººã‚ãŸã‚Šï¼‰ã®æ ¹æ‹ ãƒ‡ãƒ¼ã‚¿",
                    "url": "https://www.mhlw.go.jp/toukei/list/35-34.html",
                },
                {
                    "name": "åšç”ŸåŠ´åƒçœã€Œè–¬å±€ãƒ»è–¬å‰¤å¸«æ©Ÿèƒ½ã«é–¢ã™ã‚‹å®Ÿæ…‹èª¿æŸ»ã€",
                    "desc": f"é™¢å¤–å‡¦æ–¹ç‡ï¼ˆå…¨å›½å¹³å‡ {self.OUTPATIENT_RX_RATE:.1%}ï¼‰ã®æ ¹æ‹ ãƒ‡ãƒ¼ã‚¿",
                    "url": "https://www.mhlw.go.jp/stf/seisakunitsuite/bunya/kenkou_iryou/iyakuhin/yakkyoku_yakuzaisi/index.html",
                },
                {
                    "name": "OpenStreetMap (Overpass API)",
                    "desc": "è¿‘éš£åŒ»ç™‚æ–½è¨­ãƒ‡ãƒ¼ã‚¿ã®ã‚½ãƒ¼ã‚¹ï¼ˆåç§°ãƒ»ä½ç½®ãƒ»ã‚¿ã‚°æƒ…å ±ï¼‰",
                    "url": "https://overpass-api.de/",
                },
            ],
        )

    def _calc_pharmacy_share(
        self,
        facility: NearbyFacility,
        pharmacy_lat: float,
        pharmacy_lon: float,
        competing_pharmacies: List[NearbyFacility],
    ) -> Tuple[float, str]:
        """æ–½è¨­ã‹ã‚‰å½“è–¬å±€ã¸ã®å‡¦æ–¹ç®‹é›†å®¢ã‚·ã‚§ã‚¢ã‚’æ¨è¨ˆ"""

        dist = OverpassSearcher._haversine(
            facility.lat, facility.lon, pharmacy_lat, pharmacy_lon
        )

        # åŸºæœ¬ã‚·ã‚§ã‚¢ï¼ˆè·é›¢ãƒ™ãƒ¼ã‚¹ï¼‰
        if dist <= 50:
            base_share = 0.75
            reason = "50mä»¥å†…ï¼ˆå®Ÿè³ªé–€å‰ï¼‰"
        elif dist <= 150:
            base_share = 0.50
            reason = "150mä»¥å†…ï¼ˆè¿‘æ¥ç«‹åœ°ï¼‰"
        elif dist <= 300:
            base_share = 0.30
            reason = "300mä»¥å†…ï¼ˆå¾’æ­©åœï¼‰"
        else:
            base_share = 0.15
            reason = "500mä»¥å†…ï¼ˆè‡ªè»¢è»Šåœï¼‰"

        # ç«¶åˆè–¬å±€ã®å½±éŸ¿ã‚’è¨ˆç®—ï¼ˆæ–½è¨­è¿‘ãã®ç«¶åˆã»ã©å½±éŸ¿å¤§ï¼‰
        competing_near_facility = [
            p for p in competing_pharmacies
            if OverpassSearcher._haversine(facility.lat, facility.lon, p.lat, p.lon) < 300
        ]
        n_competitors = len(competing_near_facility)

        if n_competitors > 0:
            # ç«¶åˆãŒã„ã‚‹å ´åˆã¯ã‚·ã‚§ã‚¢ã‚’æŒ‰åˆ†
            # è·é›¢ã®é€†æ•°ã§é‡ã¿ä»˜ã‘
            target_weight = 1.0 / max(dist, 10)
            competitor_weights = [
                1.0 / max(
                    OverpassSearcher._haversine(facility.lat, facility.lon, p.lat, p.lon), 10
                )
                for p in competing_near_facility
            ]
            total_weight = target_weight + sum(competitor_weights)
            adjusted_share = base_share * (target_weight / total_weight)
            reason += f"ï¼ˆç«¶åˆ{n_competitors}ä»¶ã§æŒ‰åˆ†ï¼‰"
        else:
            adjusted_share = base_share
            reason += "ï¼ˆè¿‘éš£ã«ç«¶åˆãªã—ï¼‰"

        return min(adjusted_share, 0.90), reason


# ---------------------------------------------------------------------------
# 5. æ–¹æ³•â‘¡ å•†åœäººå£å‹•æ…‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ
# ---------------------------------------------------------------------------

class Method2Predictor:
    """
    å•†åœå†…äººå£ Ã— æ€§å¹´é½¢åˆ¥å—è¨ºç‡ Ã— å‡¦æ–¹ç®‹ç™ºè¡Œç‡ Ã— è–¬å±€å¸‚å ´ã‚·ã‚§ã‚¢ã§äºˆæ¸¬ã€‚

    ãƒ­ã‚¸ãƒƒã‚¯:
      1. å•†åœäººå£ = Ï€ Ã— åŠå¾„Â² Ã— äººå£å¯†åº¦
      2. å¹´é½¢å±¤åˆ¥: äººå£ Ã— å—è¨ºç‡/å¹´ Ã— å‡¦æ–¹ç®‹ç™ºè¡Œç‡ Ã— é™¢å¤–å‡¦æ–¹ç‡
      3. ç«¶åˆè–¬å±€ã¨ã®è·é›¢é‡ã¿ä»˜ãã‚·ã‚§ã‚¢ã‚’ä¹—ç®—
      4. â†’ å¹´é–“å‡¦æ–¹ç®‹å—ä»˜æšæ•°
    """

    def predict(
        self,
        pharmacy_lat: float,
        pharmacy_lon: float,
        competing_pharmacies: List[NearbyFacility],
        area_density: int,
        radius_m: int = 500,
    ) -> PredictionResult:
        # å•†åœäººå£
        area_km2 = math.pi * (radius_m / 1000) ** 2
        total_population = int(area_km2 * area_density)

        # å¹´é½¢å±¤åˆ¥ å¹´é–“å‡¦æ–¹ç®‹æ•°
        age_breakdown = []
        total_annual_rx_in_area = 0
        for age_grp, ratio in AGE_DISTRIBUTION.items():
            pop = int(total_population * ratio)
            visit_rate = VISIT_RATE_BY_AGE[age_grp]
            annual_visits = pop * visit_rate
            annual_rx = int(
                annual_visits
                * NATIONAL_STATS["prescription_per_visit"]
                * NATIONAL_STATS["outpatient_rx_rate"]
            )
            age_breakdown.append({
                "å¹´é½¢å±¤": age_grp,
                "æ¨è¨ˆäººå£": f"{pop:,}äºº",
                "å—è¨ºç‡": f"{visit_rate}å›/å¹´",
                "å¹´é–“å—è¨ºå›æ•°": f"{annual_visits:,.0f}å›",
                "å¹´é–“å‡¦æ–¹ç®‹æ•°": f"{annual_rx:,}æš",
            })
            total_annual_rx_in_area += annual_rx

        # å½“è–¬å±€ã®å¸‚å ´ã‚·ã‚§ã‚¢ï¼ˆè·é›¢é‡ã¿ä»˜ãï¼‰
        market_share, share_reason = self._calc_market_share(
            pharmacy_lat, pharmacy_lon, competing_pharmacies
        )

        annual_est = int(total_annual_rx_in_area * market_share)
        min_val = int(annual_est * 0.55)
        max_val = int(annual_est * 1.80)

        methodology = [
            "### æ–¹æ³•â‘¡ ãƒ­ã‚¸ãƒƒã‚¯: å•†åœäººå£å‹•æ…‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ",
            "",
            "**ç®—å‡ºå¼**:",
            "ã€€å•†åœäººå£ Ã— å¹´é½¢å±¤åˆ¥å—è¨ºç‡ Ã— å‡¦æ–¹ç®‹ç™ºè¡Œç‡(65%)",
            "ã€€Ã— é™¢å¤–å‡¦æ–¹ç‡(74.5%) Ã— å½“è–¬å±€å¸‚å ´ã‚·ã‚§ã‚¢",
            "",
            f"**å•†åœè¨­å®š**: åŠå¾„{radius_m}mï¼ˆé¢ç©: {area_km2:.2f}kmÂ²ï¼‰",
            f"**äººå£å¯†åº¦**: {area_density:,}äºº/kmÂ²ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼è¨­å®šï¼‰",
            f"**æ¨è¨ˆå•†åœäººå£**: {total_population:,}äºº",
            "",
            "**å¹´é½¢å±¤åˆ¥å¤–æ¥å—è¨ºç‡ã®æ ¹æ‹ **:",
            "ã€€ï¼ˆåšç”ŸåŠ´åƒçœã€Œæ‚£è€…èª¿æŸ»ã€2020å¹´ï¼‰",
            f"ã€€0-14æ­³: {VISIT_RATE_BY_AGE['0-14æ­³']}å›/å¹´, "
            f"15-44æ­³: {VISIT_RATE_BY_AGE['15-44æ­³']}å›/å¹´, "
            f"45-64æ­³: {VISIT_RATE_BY_AGE['45-64æ­³']}å›/å¹´,",
            f"ã€€65-74æ­³: {VISIT_RATE_BY_AGE['65-74æ­³']}å›/å¹´, "
            f"75æ­³ä»¥ä¸Š: {VISIT_RATE_BY_AGE['75æ­³ä»¥ä¸Š']}å›/å¹´",
            "",
            f"**å•†åœå†…å¹´é–“å‡¦æ–¹ç®‹ç·æ•°**: {total_annual_rx_in_area:,}æš",
            f"**å½“è–¬å±€æ¨è¨ˆå¸‚å ´ã‚·ã‚§ã‚¢**: {market_share:.1%}",
            f"  æ ¹æ‹ : {share_reason}",
            f"**æ¨è¨ˆå¹´é–“å‡¦æ–¹ç®‹æšæ•°**: **{annual_est:,}æš/å¹´**",
        ]

        return PredictionResult(
            method_name="æ–¹æ³•â‘¡: å•†åœäººå£å‹•æ…‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ",
            annual_rx=annual_est,
            min_val=min_val,
            max_val=max_val,
            confidence="low",
            daily_rx=int(annual_est / NATIONAL_STATS["working_days"]),
            breakdown=age_breakdown,
            methodology=methodology,
            references=[
                {
                    "name": "åšç”ŸåŠ´åƒçœã€Œæ‚£è€…èª¿æŸ»ã€2020å¹´",
                    "desc": "å¹´é½¢å±¤åˆ¥å¤–æ¥å—è¨ºç‡ï¼ˆå›/å¹´/äººï¼‰ã®æ ¹æ‹ ãƒ‡ãƒ¼ã‚¿",
                    "url": "https://www.mhlw.go.jp/toukei/saikin/hw/kanja/20/index.html",
                },
                {
                    "name": "ç·å‹™çœã€Œå›½å‹¢èª¿æŸ»ã€2020å¹´",
                    "desc": "æ—¥æœ¬ã®å¹´é½¢åˆ¥äººå£åˆ†å¸ƒï¼ˆ2020å¹´ï¼‰",
                    "url": "https://www.stat.go.jp/data/kokusei/2020/",
                },
                {
                    "name": "åšç”ŸåŠ´åƒçœã€Œèª¿å‰¤åŒ»ç™‚è²»ã®å‹•å‘ã€2022å¹´åº¦",
                    "desc": f"é™¢å¤–å‡¦æ–¹ç‡ {NATIONAL_STATS['outpatient_rx_rate']:.1%} ã®æ ¹æ‹ ãƒ‡ãƒ¼ã‚¿",
                    "url": NATIONAL_STATS["source_url"] if "source_url" in NATIONAL_STATS else "https://www.mhlw.go.jp/topics/medias/med/",
                },
            ],
        )

    def _calc_market_share(
        self,
        pharmacy_lat: float,
        pharmacy_lon: float,
        competing_pharmacies: List[NearbyFacility],
    ) -> Tuple[float, str]:
        n = len(competing_pharmacies)
        if n == 0:
            return 0.65, "å•†åœå†…ã«ç«¶åˆè–¬å±€ãªã—ï¼ˆç‹¬å è£œæ­£0.65ï¼‰"

        # è·é›¢ã®é€†æ•°Â²ã§é‡ã¿ä»˜ã‘ã‚·ã‚§ã‚¢ã‚’è¨ˆç®—
        target_weight = 1.0  # å½“è–¬å±€ã¯è·é›¢0
        competitor_weights = [
            1.0 / max(p.distance_m, 20) ** 2
            for p in competing_pharmacies
        ]
        total_weight = target_weight + sum(competitor_weights)
        raw_share = target_weight / total_weight

        share = min(raw_share, 0.80)
        return share, f"è·é›¢é‡ã¿ä»˜ãã‚·ã‚§ã‚¢ï¼ˆç«¶åˆ{n}ä»¶ï¼‰: {share:.1%}"


# ---------------------------------------------------------------------------
# 6. ç«¶åˆãƒãƒƒãƒ—ï¼ˆFoliumï¼‰
# ---------------------------------------------------------------------------

def build_competitor_map(
    pharmacy_name: str,
    pharmacy_lat: float,
    pharmacy_lon: float,
    medical_facilities: List[NearbyFacility],
    competing_pharmacies: List[NearbyFacility],
    radius_m: int = 500,
) -> folium.Map:
    """è¿‘éš£æ–½è¨­ã‚’è¡¨ç¤ºã™ã‚‹Foliumãƒãƒƒãƒ—ã‚’ç”Ÿæˆ"""

    m = folium.Map(
        location=[pharmacy_lat, pharmacy_lon],
        zoom_start=16,
        tiles="OpenStreetMap",
    )

    # å•†åœå††
    folium.Circle(
        location=[pharmacy_lat, pharmacy_lon],
        radius=radius_m,
        color="#FF4444",
        fill=True,
        fill_opacity=0.05,
        weight=2,
        popup=f"å•†åœåŠå¾„ {radius_m}m",
    ).add_to(m)

    # å¯¾è±¡è–¬å±€ï¼ˆèµ¤ãƒ»å¤§ãƒãƒ¼ã‚«ãƒ¼ï¼‰
    folium.Marker(
        location=[pharmacy_lat, pharmacy_lon],
        popup=folium.Popup(
            f"<b>ğŸ’Š {pharmacy_name}</b><br>ã€åˆ†æå¯¾è±¡è–¬å±€ã€‘",
            max_width=200,
        ),
        tooltip=f"ğŸ’Š {pharmacy_name}ï¼ˆåˆ†æå¯¾è±¡ï¼‰",
        icon=folium.Icon(color="red", icon="plus-sign", prefix="glyphicon"),
    ).add_to(m)

    # åŒ»ç™‚æ–½è¨­
    for fac in medical_facilities:
        color = "blue" if fac.facility_type == "hospital" else "cadetblue"
        icon_name = "h-sign" if fac.facility_type == "hospital" else "user-md"
        ftype_label = "ğŸ¥ ç—…é™¢" if fac.facility_type == "hospital" else "ğŸ¨ ã‚¯ãƒªãƒ‹ãƒƒã‚¯"
        inhouse_note = "ï¼ˆé™¢å†…è–¬å±€ã‚ã‚Šï¼‰" if fac.has_inhouse_pharmacy else ""
        popup_html = (
            f"<b>{ftype_label} {fac.name}</b>{inhouse_note}<br>"
            f"è¨ºç™‚ç§‘: {fac.specialty}<br>"
            f"è·é›¢: {fac.distance_m:.0f}m<br>"
            f"æ¨è¨ˆå¤–æ¥: {fac.daily_outpatients}äºº/æ—¥"
        )
        if fac.mhlw_annual_outpatients:
            popup_html += f"<br>MHLWå¹´é–“å¤–æ¥: {fac.mhlw_annual_outpatients:,}äºº"

        folium.Marker(
            location=[fac.lat, fac.lon],
            popup=folium.Popup(popup_html, max_width=250),
            tooltip=f"{ftype_label} {fac.name} ({fac.distance_m:.0f}m)",
            icon=folium.Icon(color=color, icon=icon_name, prefix="glyphicon"),
        ).add_to(m)

        # æ–½è¨­ã¨å¯¾è±¡è–¬å±€ã‚’çµã¶ç·š
        folium.PolyLine(
            [[fac.lat, fac.lon], [pharmacy_lat, pharmacy_lon]],
            color=color, weight=1.5, opacity=0.5,
        ).add_to(m)

    # ç«¶åˆè–¬å±€ï¼ˆç·‘ãƒãƒ¼ã‚«ãƒ¼ï¼‰
    for ph in competing_pharmacies:
        is_chain = any(c in ph.name for c in MAJOR_CHAINS)
        chain_note = "ï¼ˆå¤§æ‰‹ãƒã‚§ãƒ¼ãƒ³ï¼‰" if is_chain else ""
        popup_html = (
            f"<b>ğŸ’Š {ph.name}</b>{chain_note}<br>"
            f"è·é›¢: {ph.distance_m:.0f}m"
        )
        folium.Marker(
            location=[ph.lat, ph.lon],
            popup=folium.Popup(popup_html, max_width=200),
            tooltip=f"ğŸ’Š ç«¶åˆ: {ph.name} ({ph.distance_m:.0f}m)",
            icon=folium.Icon(color="green", icon="shopping-cart", prefix="glyphicon"),
        ).add_to(m)

    return m


# ---------------------------------------------------------------------------
# 7. ä¹–é›¢è©•ä¾¡
# ---------------------------------------------------------------------------

def calc_deviation(actual: int, predicted: int) -> Tuple[float, str, str]:
    """å®Ÿç¸¾å€¤ã¨äºˆæ¸¬å€¤ã®ä¹–é›¢ç‡ã‚’è¨ˆç®—"""
    if actual <= 0:
        return 0.0, "N/A", "neutral"
    pct = (predicted - actual) / actual * 100
    label = f"+{pct:.1f}%" if pct >= 0 else f"{pct:.1f}%"
    color = "normal" if abs(pct) < 20 else ("inverse" if abs(pct) < 50 else "off")
    return pct, label, color


# ---------------------------------------------------------------------------
# 8. Streamlit UI
# ---------------------------------------------------------------------------

def render_comparison_banner(analysis: FullAnalysis) -> None:
    """å®Ÿç¸¾å€¤ vs æ–¹æ³•â‘ â‘¡ ã®æ¯”è¼ƒãƒãƒŠãƒ¼ã‚’è¡¨ç¤º"""
    st.markdown("## ğŸ“Š äºˆæ¸¬å€¤ vs åšåŠ´çœå®Ÿç¸¾å€¤ æ¯”è¼ƒ")

    actual = analysis.mhlw_annual_rx
    m1 = analysis.method1
    m2 = analysis.method2

    cols = st.columns(4)

    # å®Ÿç¸¾å€¤
    with cols[0]:
        if actual:
            st.metric(
                "ğŸ¥ MHLWå®Ÿç¸¾å€¤",
                f"{actual:,} æš/å¹´",
                help="åšç”ŸåŠ´åƒçœã€Œè–¬å±€æ©Ÿèƒ½æƒ…å ±æä¾›åˆ¶åº¦ã€ã®ç·å–æ‰±å‡¦æ–¹ç®‹æ•°ï¼ˆå‰å¹´1å¹´é–“ï¼‰",
            )
            st.caption("ğŸŸ¢ ä¿¡é ¼åº¦: é«˜ï¼ˆå®Ÿç¸¾å€¤ï¼‰")
        else:
            st.metric("ğŸ¥ MHLWå®Ÿç¸¾å€¤", "è¨˜è¼‰ãªã—")
            st.caption("âš  å½“è©²è–¬å±€ã¯æœªå ±å‘Š")

    # æ–¹æ³•â‘ 
    with cols[1]:
        if m1:
            st.metric(
                "â‘  åŒ»ç™‚æ©Ÿé–¢ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ",
                f"{m1.annual_rx:,} æš/å¹´",
                delta=calc_deviation(actual, m1.annual_rx)[1] if actual else None,
            )
            st.caption(f"ãƒ¬ãƒ³ã‚¸: {m1.min_val:,}ã€œ{m1.max_val:,}")

    # æ–¹æ³•â‘¡
    with cols[2]:
        if m2:
            st.metric(
                "â‘¡ äººå£å‹•æ…‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ",
                f"{m2.annual_rx:,} æš/å¹´",
                delta=calc_deviation(actual, m2.annual_rx)[1] if actual else None,
            )
            st.caption(f"ãƒ¬ãƒ³ã‚¸: {m2.min_val:,}ã€œ{m2.max_val:,}")

    # ä¹–é›¢ã‚µãƒãƒªãƒ¼
    with cols[3]:
        if actual and m1 and m2:
            avg_pred = (m1.annual_rx + m2.annual_rx) // 2
            pct, label, _ = calc_deviation(actual, avg_pred)
            st.metric(
                "äºˆæ¸¬å¹³å‡ vs å®Ÿç¸¾",
                f"{avg_pred:,} æš/å¹´",
                delta=label,
                delta_color="normal" if abs(pct) < 30 else "inverse",
            )
            st.caption("ï¼ˆâ‘ ã¨â‘¡ã®å˜ç´”å¹³å‡ï¼‰")


def render_competitor_table(
    medical_facilities: List[NearbyFacility],
    competing_pharmacies: List[NearbyFacility],
) -> None:
    """ç«¶åˆç’°å¢ƒãƒ†ãƒ¼ãƒ–ãƒ«ã‚’è¡¨ç¤º"""
    st.markdown("### ğŸ—º è¿‘éš£ã®åŒ»ç™‚æ–½è¨­ãƒ»ç«¶åˆè–¬å±€")

    col_med, col_ph = st.columns(2)
    with col_med:
        st.markdown(f"**åŒ»ç™‚æ–½è¨­ï¼ˆ{len(medical_facilities)}ä»¶ï¼‰**")
        if medical_facilities:
            rows = []
            for f in medical_facilities:
                rows.append({
                    "æ–½è¨­å": f.name,
                    "ç¨®åˆ¥": "ç—…é™¢" if f.facility_type == "hospital" else "ã‚¯ãƒªãƒ‹ãƒƒã‚¯",
                    "è·é›¢": f"{f.distance_m:.0f}m",
                    "è¨ºç™‚ç§‘": f.specialty,
                    "å¤–æ¥/æ—¥(æ¨è¨ˆ)": f"{f.daily_outpatients}äºº",
                    "é™¢å†…è–¬å±€": "ã‚ã‚Š" if f.has_inhouse_pharmacy else "ãªã—",
                })
            import pandas as pd
            st.dataframe(pd.DataFrame(rows), use_container_width=True, hide_index=True)
        else:
            st.info("è¿‘éš£500mä»¥å†…ã«åŒ»ç™‚æ–½è¨­ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")

    with col_ph:
        st.markdown(f"**ç«¶åˆè–¬å±€ï¼ˆ{len(competing_pharmacies)}ä»¶ï¼‰**")
        if competing_pharmacies:
            rows = []
            for p in competing_pharmacies:
                rows.append({
                    "è–¬å±€å": p.name,
                    "è·é›¢": f"{p.distance_m:.0f}m",
                    "ãƒã‚§ãƒ¼ãƒ³": "ã¯ã„" if any(c in p.name for c in MAJOR_CHAINS) else "ç‹¬ç«‹",
                })
            import pandas as pd
            st.dataframe(pd.DataFrame(rows), use_container_width=True, hide_index=True)
        else:
            st.info("è¿‘éš£500mä»¥å†…ã«ç«¶åˆè–¬å±€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")


def main() -> None:
    st.set_page_config(
        page_title="è–¬å±€ å‡¦æ–¹ç®‹æšæ•° å¤šé¢çš„äºˆæ¸¬ v2",
        page_icon="ğŸ”¬",
        layout="wide",
        initial_sidebar_state="collapsed",
    )

    st.title("ğŸ”¬ è–¬å±€ å¹´é–“å‡¦æ–¹ç®‹æšæ•° å¤šé¢çš„äºˆæ¸¬ãƒ„ãƒ¼ãƒ« v2.0")
    st.markdown(
        "åšç”ŸåŠ´åƒçœã®å®Ÿç¸¾ãƒ‡ãƒ¼ã‚¿ã¨ã€**è¿‘éš£åŒ»ç™‚æ©Ÿé–¢ã‚¢ãƒ—ãƒ­ãƒ¼ãƒï¼ˆæ–¹æ³•â‘ ï¼‰**ãƒ»"
        "**å•†åœäººå£å‹•æ…‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒï¼ˆæ–¹æ³•â‘¡ï¼‰** ã®2ç¨®é¡ã®äºˆæ¸¬ã‚’ä¸¦åˆ—è¡¨ç¤ºã—ã€"
        "å®Ÿç¸¾å€¤ã¨ã®ä¹–é›¢ã‚’è©•ä¾¡ã—ã¾ã™ã€‚ç«¶åˆãƒãƒƒãƒ—ã‚‚æä¾›ã—ã¾ã™ã€‚"
    )

    # session_state åˆæœŸåŒ–
    for k, v in [
        ("candidates", []),
        ("selected_idx", 0),
        ("analysis", None),
        ("search_done", False),
    ]:
        if k not in st.session_state:
            st.session_state[k] = v

    # ==============================================================
    # STEP 1: è–¬å±€æ¤œç´¢
    # ==============================================================
    st.markdown("### STEP 1 â€” è–¬å±€åã§æ¤œç´¢ï¼ˆåšç”ŸåŠ´åƒçœãƒãƒ¼ã‚¿ãƒ«ï¼‰")

    col_kw, col_pref = st.columns([3, 1])
    with col_kw:
        keyword = st.text_input(
            "è–¬å±€åï¼ˆä¸€éƒ¨ã§ã‚‚å¯ï¼‰",
            placeholder="ä¾‹: ã‚¢ã‚¤ã‚»ã‚¤è–¬å±€ æ­¦è”µå°æ‰ / æ—¥æœ¬èª¿å‰¤ æ–°å®¿",
            key="v2_keyword",
        )
    with col_pref:
        prefecture = st.selectbox("éƒ½é“åºœçœŒï¼ˆä»»æ„ï¼‰", ["ï¼ˆæŒ‡å®šãªã—ï¼‰"] + PREFECTURES, key="v2_pref")

    if st.button("ğŸ” å€™è£œã‚’æ¤œç´¢", type="primary"):
        st.session_state["analysis"] = None
        st.session_state["search_done"] = False
        pref_code = PREFECTURE_CODES.get(prefecture, "")
        with st.spinner("MHLWãƒãƒ¼ã‚¿ãƒ«ã‚’æ¤œç´¢ä¸­â€¦"):
            scraper = MHLWScraper()
            candidates, total, status = scraper.search_pharmacy_candidates(keyword.strip(), pref_code)
        st.session_state["candidates"] = candidates
        if candidates:
            st.success(f"âœ… {status}ï¼ˆå…¨{total}ä»¶ï¼‰")
        else:
            st.warning("å€™è£œãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")

    # ==============================================================
    # STEP 2: å€™è£œé¸æŠ + åˆ†æãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š
    # ==============================================================
    candidates: List[PharmacyCandidate] = st.session_state.get("candidates", [])
    analysis: Optional[FullAnalysis] = st.session_state.get("analysis")

    if candidates and analysis is None:
        st.markdown("---")
        st.markdown("### STEP 2 â€” è–¬å±€é¸æŠã¨åˆ†æãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š")

        options = [
            f"{c.name}ã€€{'ï¼ˆ' + c.address[:35] + 'ï¼‰' if c.address else ''}"
            for c in candidates
        ]
        sel_label = st.selectbox("å€™è£œä¸€è¦§", options, key="v2_candidate_select")
        sel_idx = options.index(sel_label)
        sel_candidate = candidates[sel_idx]
        st.caption(f"ğŸ“ ä½æ‰€: {sel_candidate.address or 'ä¸æ˜'}")

        st.markdown("**åˆ†æãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆæ–¹æ³•â‘¡ã®å•†åœè¨­å®šï¼‰**")
        col_a, col_b, col_c = st.columns(3)
        with col_a:
            area_type = st.selectbox(
                "å•†åœã®äººå£å¯†åº¦",
                list(AREA_DENSITY_OPTIONS.keys()),
                index=2,
                help="è–¬å±€å‘¨è¾ºã®å¸‚è¡—åœ°ã‚¿ã‚¤ãƒ—ã‚’é¸æŠã—ã¦ãã ã•ã„",
            )
        with col_b:
            radius = st.slider("å•†åœåŠå¾„ï¼ˆmï¼‰", 200, 1000, 500, step=100)
        with col_c:
            try_mhlw_medical = st.checkbox(
                "è¿‘éš£åŒ»ç™‚æ–½è¨­ã®MHLWãƒ‡ãƒ¼ã‚¿ç…§ä¼š", value=False,
                help="ONã«ã™ã‚‹ã¨ç²¾åº¦ãŒä¸ŠãŒã‚Šã¾ã™ãŒã€æ¤œç´¢ã«æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™ï¼ˆå„æ–½è¨­ã”ã¨ã«MHLWã«å•ã„åˆã‚ã›ï¼‰",
            )

        if st.button("ğŸš€ å¤šé¢çš„åˆ†æã‚’å®Ÿè¡Œ", type="primary", use_container_width=True):
            run_analysis(sel_candidate, area_type, radius, try_mhlw_medical)

    # ==============================================================
    # STEP 3: çµæœè¡¨ç¤º
    # ==============================================================
    if analysis:
        st.markdown("---")
        st.markdown(f"## çµæœ: `{analysis.pharmacy_name}`")
        st.caption(f"ä½æ‰€: {analysis.pharmacy_address}")

        # æ¯”è¼ƒãƒãƒŠãƒ¼
        render_comparison_banner(analysis)
        st.markdown("---")

        # ãƒ¡ã‚¤ãƒ³ã‚¿ãƒ–
        tab_map, tab_m1, tab_m2, tab_mhlw, tab_log = st.tabs([
            "ğŸ—º ç«¶åˆãƒãƒƒãƒ—",
            "â‘  åŒ»ç™‚æ©Ÿé–¢ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ",
            "â‘¡ äººå£å‹•æ…‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ",
            "ğŸ¥ åšåŠ´çœãƒ‡ãƒ¼ã‚¿",
            "ğŸ” æ¤œç´¢ãƒ­ã‚°",
        ])

        with tab_map:
            if analysis.pharmacy_lat and analysis.pharmacy_lon:
                st.markdown("**å‡¡ä¾‹**: ğŸ”´ åˆ†æå¯¾è±¡è–¬å±€ã€€ğŸ”µ ç—…é™¢ã€€ğŸ”· ã‚¯ãƒªãƒ‹ãƒƒã‚¯ã€€ğŸŸ¢ ç«¶åˆè–¬å±€")
                folium_map = build_competitor_map(
                    analysis.pharmacy_name,
                    analysis.pharmacy_lat,
                    analysis.pharmacy_lon,
                    analysis.nearby_medical,
                    analysis.nearby_pharmacies,
                )
                st_folium(folium_map, width=None, height=500, use_container_width=True)
                render_competitor_table(analysis.nearby_medical, analysis.nearby_pharmacies)
            else:
                st.warning("ä½æ‰€ã‹ã‚‰åº§æ¨™ã‚’å–å¾—ã§ããªã‹ã£ãŸãŸã‚ã€ãƒãƒƒãƒ—ã‚’è¡¨ç¤ºã§ãã¾ã›ã‚“")
                render_competitor_table(analysis.nearby_medical, analysis.nearby_pharmacies)

        with tab_m1:
            if analysis.method1:
                m1 = analysis.method1
                st.metric("å¹´é–“æ¨è¨ˆå‡¦æ–¹ç®‹æšæ•°ï¼ˆæ–¹æ³•â‘ ï¼‰", f"{m1.annual_rx:,} æš/å¹´")
                st.caption(f"ãƒ¬ãƒ³ã‚¸: {m1.min_val:,}ã€œ{m1.max_val:,}æš/å¹´ | 1æ—¥æ›ç®—: {m1.daily_rx}æš/æ—¥")
                if m1.breakdown:
                    st.markdown("#### æ–½è¨­åˆ¥ å‡¦æ–¹ç®‹æµå…¥å†…è¨³")
                    import pandas as pd
                    df = pd.DataFrame(m1.breakdown)
                    st.dataframe(df, use_container_width=True, hide_index=True)
                st.markdown("#### æ¨è¨ˆãƒ­ã‚¸ãƒƒã‚¯")
                for line in m1.methodology:
                    st.markdown(line)
                st.markdown("#### å‚ç…§ã‚½ãƒ¼ã‚¹")
                for ref in m1.references:
                    with st.expander(ref["name"]):
                        st.write(ref.get("desc", ""))
                        if ref.get("url"):
                            st.markdown(f"ğŸ”— [{ref['url']}]({ref['url']})")
            else:
                st.info("æ–¹æ³•â‘ ã®åˆ†æãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")

        with tab_m2:
            if analysis.method2:
                m2 = analysis.method2
                st.metric("å¹´é–“æ¨è¨ˆå‡¦æ–¹ç®‹æšæ•°ï¼ˆæ–¹æ³•â‘¡ï¼‰", f"{m2.annual_rx:,} æš/å¹´")
                st.caption(f"ãƒ¬ãƒ³ã‚¸: {m2.min_val:,}ã€œ{m2.max_val:,}æš/å¹´ | 1æ—¥æ›ç®—: {m2.daily_rx}æš/æ—¥")
                if m2.breakdown:
                    st.markdown("#### å¹´é½¢å±¤åˆ¥ å‡¦æ–¹ç®‹æ•°å†…è¨³")
                    import pandas as pd
                    df = pd.DataFrame(m2.breakdown)
                    st.dataframe(df, use_container_width=True, hide_index=True)
                st.markdown("#### æ¨è¨ˆãƒ­ã‚¸ãƒƒã‚¯")
                for line in m2.methodology:
                    st.markdown(line)
                st.markdown("#### å‚ç…§ã‚½ãƒ¼ã‚¹")
                for ref in m2.references:
                    with st.expander(ref["name"]):
                        st.write(ref.get("desc", ""))
                        if ref.get("url"):
                            st.markdown(f"ğŸ”— [{ref['url']}]({ref['url']})")
            else:
                st.info("æ–¹æ³•â‘¡ã®åˆ†æãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")

        with tab_mhlw:
            if analysis.mhlw_annual_rx:
                st.success(f"âœ… åšåŠ´çœå®Ÿç¸¾å€¤: **{analysis.mhlw_annual_rx:,}æš/å¹´**")
                st.markdown(f"ğŸ”— [MHLWãƒãƒ¼ã‚¿ãƒ«ã§ç¢ºèª]({analysis.mhlw_source_url})")
            else:
                st.warning("åšåŠ´çœãƒãƒ¼ã‚¿ãƒ«ã«å‡¦æ–¹ç®‹æšæ•°ã®è¨˜è¼‰ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸï¼ˆæœªå ±å‘Šï¼‰")
                if analysis.mhlw_source_url:
                    st.markdown(f"ğŸ”— [MHLWãƒãƒ¼ã‚¿ãƒ«ã§ç¢ºèª]({analysis.mhlw_source_url})")

        with tab_log:
            st.code("\n".join(analysis.search_log))

    # åˆæœŸç”»é¢
    if not candidates and analysis is None:
        st.markdown("---")
        col1, col2, col3 = st.columns(3)
        col1.markdown(
            "**â‘  åšåŠ´çœå®Ÿãƒ‡ãƒ¼ã‚¿å–å¾—**\n\n"
            "è–¬å±€æ©Ÿèƒ½æƒ…å ±æä¾›åˆ¶åº¦ã‹ã‚‰\nã€Œç·å–æ‰±å‡¦æ–¹ç®‹æ•°ã€ã‚’ç›´æ¥å–å¾—"
        )
        col2.markdown(
            "**â‘¡ è¿‘éš£åŒ»ç™‚æ©Ÿé–¢ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ**\n\n"
            "OSMã§è¿‘éš£ã‚¯ãƒªãƒ‹ãƒƒã‚¯ãƒ»ç—…é™¢ã‚’æ¤œç´¢ã—\nè¨ºç™‚ç§‘åˆ¥å‡¦æ–¹ç®‹ç™ºè¡Œç‡ã‹ã‚‰äºˆæ¸¬"
        )
        col3.markdown(
            "**â‘¢ å•†åœäººå£å‹•æ…‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ**\n\n"
            "å•†åœäººå£ Ã— å¹´é½¢åˆ¥å—è¨ºç‡ Ã—\nå‡¦æ–¹ç®‹ç™ºè¡Œç‡ Ã— å¸‚å ´ã‚·ã‚§ã‚¢ã§äºˆæ¸¬"
        )


def run_analysis(
    candidate: PharmacyCandidate,
    area_type: str,
    radius: int,
    try_mhlw_medical: bool,
) -> None:
    """ãƒ•ãƒ«åˆ†æã‚’å®Ÿè¡Œã—ã¦ session_state ã«ä¿å­˜"""
    log = []
    progress = st.progress(0, text="åˆ†æé–‹å§‹â€¦")

    # â”€â”€ STEP A: MHLWã‹ã‚‰è–¬å±€è©³ç´°ã‚’å–å¾—
    progress.progress(10, text="[1/5] MHLW: è–¬å±€è©³ç´°ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­â€¦")
    scraper = MHLWScraper()
    scraper.initialize_session()
    detail, detail_msg = scraper.get_pharmacy_detail(candidate)
    log.append(f"[MHLW è–¬å±€è©³ç´°] {detail_msg}")

    mhlw_annual_rx = None
    pharmacy_address = candidate.address
    mhlw_source_url = candidate.href

    if detail:
        mhlw_annual_rx = detail.get("prescriptions_annual")
        if detail.get("address"):
            pharmacy_address = detail["address"]
        mhlw_source_url = detail.get("source_url", candidate.href)
        log.append(f"  å‡¦æ–¹ç®‹æ•°: {mhlw_annual_rx}æš/å¹´" if mhlw_annual_rx else "  å‡¦æ–¹ç®‹æ•°: è¨˜è¼‰ãªã—")

    # â”€â”€ STEP B: ã‚¸ã‚ªã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
    progress.progress(25, text="[2/5] ä½æ‰€ã‚’åº§æ¨™ã«å¤‰æ›ä¸­ï¼ˆNominatimï¼‰â€¦")
    geocoder = GeocoderService()
    lat, lon, geo_msg = geocoder.geocode(pharmacy_address)
    log.append(f"[Geocoding] {geo_msg}")
    if lat:
        log.append(f"  åº§æ¨™: ({lat:.5f}, {lon:.5f})")
    else:
        log.append("  âš  åº§æ¨™å–å¾—å¤±æ•— â†’ ç©ºé–“åˆ†æã‚’ã‚¹ã‚­ãƒƒãƒ—")

    # â”€â”€ STEP C: è¿‘éš£æ–½è¨­æ¤œç´¢ï¼ˆOSMï¼‰
    nearby_medical: List[NearbyFacility] = []
    nearby_pharmacies: List[NearbyFacility] = []

    if lat and lon:
        progress.progress(45, text="[3/5] è¿‘éš£æ–½è¨­ã‚’OSMã‹ã‚‰æ¤œç´¢ä¸­â€¦")
        time.sleep(1)  # Nominatimåˆ©ç”¨è¦ç´„: 1ç§’ä»¥ä¸Šã®é–“éš”
        overpass = OverpassSearcher()
        nearby_medical, nearby_pharmacies, osm_msg = overpass.search_nearby(lat, lon, radius)
        log.append(f"[OSM Overpass] {osm_msg}")

        # MHLWã§å„åŒ»ç™‚æ–½è¨­ã®å¤–æ¥æ‚£è€…æ•°ã‚’å–å¾—ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        if try_mhlw_medical and nearby_medical:
            progress.progress(55, text="[3.5/5] è¿‘éš£åŒ»ç™‚æ–½è¨­ã®MHLWãƒ‡ãƒ¼ã‚¿ã‚’ç…§ä¼šä¸­â€¦")
            for i, fac in enumerate(nearby_medical[:5]):  # æœ€å¤§5æ–½è¨­
                annual_op = scraper.get_medical_outpatient_data(fac.name)
                if annual_op:
                    fac.mhlw_annual_outpatients = annual_op
                    fac.daily_outpatients = annual_op // NATIONAL_STATS["working_days"]
                    log.append(f"  [MHLWåŒ»ç™‚æ©Ÿé–¢] {fac.name}: å¹´é–“å¤–æ¥{annual_op:,}äºº")
                time.sleep(0.5)

    # â”€â”€ STEP D: æ–¹æ³•â‘ äºˆæ¸¬
    progress.progress(70, text="[4/5] æ–¹æ³•â‘ : è¿‘éš£åŒ»ç™‚æ©Ÿé–¢ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§äºˆæ¸¬ä¸­â€¦")
    m1_predictor = Method1Predictor()
    method1 = m1_predictor.predict(
        lat or 0.0, lon or 0.0, nearby_medical, nearby_pharmacies
    ) if lat else None
    log.append(f"[æ–¹æ³•â‘ ] æ¨è¨ˆ: {method1.annual_rx:,}æš/å¹´" if method1 else "[æ–¹æ³•â‘ ] ã‚¹ã‚­ãƒƒãƒ—ï¼ˆåº§æ¨™ãªã—ï¼‰")

    # â”€â”€ STEP E: æ–¹æ³•â‘¡äºˆæ¸¬
    progress.progress(85, text="[5/5] æ–¹æ³•â‘¡: å•†åœäººå£å‹•æ…‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§äºˆæ¸¬ä¸­â€¦")
    area_density = AREA_DENSITY_OPTIONS[area_type]
    m2_predictor = Method2Predictor()
    method2 = m2_predictor.predict(
        lat or 0.0, lon or 0.0, nearby_pharmacies, area_density, radius
    )
    log.append(f"[æ–¹æ³•â‘¡] æ¨è¨ˆ: {method2.annual_rx:,}æš/å¹´")

    progress.progress(100, text="å®Œäº†ï¼")
    progress.empty()

    # çµæœã‚’ session_state ã«ä¿å­˜
    st.session_state["analysis"] = FullAnalysis(
        pharmacy_name=candidate.name,
        pharmacy_address=pharmacy_address,
        pharmacy_lat=lat or 0.0,
        pharmacy_lon=lon or 0.0,
        mhlw_annual_rx=mhlw_annual_rx,
        mhlw_source_url=mhlw_source_url,
        method1=method1,
        method2=method2,
        nearby_medical=nearby_medical,
        nearby_pharmacies=nearby_pharmacies,
        search_log=log,
    )
    st.session_state["search_done"] = True
    st.rerun()


if __name__ == "__main__":
    main()
